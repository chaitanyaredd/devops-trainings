# OneNote Export

=
24
November 2023
14:=
30
🚀
Easy Apply Experts : Job Application
Assistant
🚀
&=
nbsp;
We handle the =
entire
job application process for you, applying to positions that match your skil=
ls
and preferences across various job portals.
Please revert =
us if
you are interested.
🚀
Master Automation Testing with Our
Selenium
Course! Unlock Your Testing
Potential Today!
🚀
We provide tra=
ining
on Selenium with our best real-time trainers.
Progr=
am
Details
:
Name of the course: "
SELENIUM
"
Trainer:
Ram
Duration:45 days
.
Revert me for =
more
details.
Integr=
ation
of Maven with Jfrog
17
September 2023
23:=
41
Better=
 to
include
23
November 2023
17:=
12
Zip a file us=
ing
      zip
Unzip
Tar -cvf
Tar -xzvf
Change jenkins home
      directory
Email setup jenkins
Introd=
uction-Day-1
22
December 2023
20:=
35
AWS-DAY-1
DEVOPS course alone is =
not
     sufficient to crack any devops interview now a days, as a devops engin=
eers
     we should aware of any one of the cloud platforms like AWS/Azure/GCP.<=
/span>
=
It's even much more bet=
ter to
     have the knowledge on AWS & AZURE both, you will have chance to get
     more interview calls.
Why because you will get mor=
e calls?
Almost every company now following devops
practices
& also they are migrating their infra either to AWS or A=
ZURE,
If you have knowledge on both cloud platforms you will become one of the ch=
oice
for them.
=
In this c=
ourse I
     will teach only the AWS & that too I will cover major resources in
     DEVOPS that are needed for 3-6
years' experience of
devops
     engineers.
=
Today's agenda is
AWS Global Infrastructu=
re
Create AWS trail accoun=
t
Launch an EC2 & Con=
nect
     to it
In AWS global infrastru=
cture
     we mainly discuss about
regions
and
availability zones
.
Now
let's talk about regions.
What is
     region?
It's a geographical loc=
ations
     of aws across the world.
So let me open the
AWS g=
lobal
     infrastructure page.
In
this page you can see there are 30 regions across the world the AWS doing i=
ts
operations.
Blue
dots refers to the already existed and actively running regions and their R=
ed
dots refers to the this are the new upcoming regions.
Each region consists of=
 a
     cluster of two or many data centres and these data centres we can cons=
ider
     availability zones.
In India as of now we =
have
      to regions one is in Mumbai and another one is Hyderabad.
In Hyderabad region we=
 have
      three availability zones and in Mumbai region we have to availability
      zones so you can simply assume availability zone is nothing but a data
      centre.
Now let me explain this
     regions and availability zones in diagrammatic way for better clarity.=
Linux-=
Day-1
13
October 2023
00:=
26
LINUX
Today session =
is on
Linux operating system. Before we jump into the class,
You gu=
ys
     already having
knowledge on =
Linux
     operating system?
If you don't =
have
      knowledge on LINUX operating system no worries I will explain it from=
 the
      scratch.
If you have knowledge =
on the
      Linux operating system it's well and good please listen one more time=
 and
      don't get bored.
Can so=
meone
     tell what is an operating system?
It's an interface betw=
een
      the user and system.
Image-1
So user will communicat=
e with
     operating system and operating system will communicate with the machin=
e.
What a=
re the
     popular operating systems in the market?
Windows
Unix
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
WINDOWS
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Who is=
 the
     owner/vendor for the windows operating systems?
Microsoft is the owner=
 of
      the windows operating system.
If anyone wants to ins=
tall
      windows operating system on any laptops they have to purchase the lic=
ence
      from Microsoft.
I mean windows operati=
ng
      systems are not open source operating system.
What i=
s open
     source? -
Tuning requir=
ed
The
sour=
ce
      code which is developed
for windows operating system is
not s=
hared
      with public users for free
.
Only the vendor have
      authority to modify the source code of windows operating system so
      windows is not open source operating system.
What a=
re the
     different flavours of the windows operating system?
Windows Vista
Windows XP
Windows 2008
Windows 2009
Windows 2011
In this different flavo=
urs of
     windows operating system 90% of the core functionalities are mostly sa=
me
     and only 10% futures are different in the each operating systems.
I mean there will be al=
most
     10% delta portion between windows Vista and windows XP operating syste=
ms,
     rest of the core functionalities will be same.
Have y=
ou
     observe so far in the windows I discussed only user desktop level
     operating systems.
I
mean the operating systems windows Vista, windows XP, windows 2008 2009 2011
are installed in the users laptops.
Micros=
oft
     developed server level operating systems also at windows side, the ser=
ver
     side flavours of windows operating systems are
Windows 2012 server
Windows 2016 server
Windows 2019 server
Windows 2022 server
This
flavours of windows operating systems are installed in server machines.
What is
     server and desktop?
Desktop:
it's a machine normally that you=
 are
using with the normal configurations.
Server:
It's a machine with higher
configurations in terms of number of CPU, Ram and disk size.
Machines that are provided from
AWS/Azure/gcp those machines also will be considered as servers.
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
UNIX
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Now let's jump=
 into
the Unix operating system
Many p=
eople
     assume UNIX and LINUX are same operating system is this really true?
No
the UNIX & Linux are both are supporting operating system I will discus=
s on
this now,
Unix
operating system inven=
ted at
Bell
     Lab's
and =
this
UNIX <=
/span>
operating system is not=
 an
     open source operating system if anyone wants to use in its operating
     system they need to purchase licence from Bell Labs.
When this
UNIX <=
/span>
operating system invent=
ed
     this is become very popular at university level and research side.
So now major companies =
like
IBM
HP
Sun Solaris
Fujistu
made
agreement with
Bell Lab's for
developing their own operating system based on =
Unix
operating system source code.
IBM
     developed =3D=3D> AIX based out of Unix operating system source cod=
e
Sun So=
laris
     =3D=3D> Solaris OS
HP
=3D=3D> HP-UX OS
Fujist=
u
=3D=3D> UXP/DS OS
So now all these are be=
came
     the flavours of Unix operating system.
I mean it's
AIX
Solaris
HP-UX
UXP/DS
all are
flavours of the Unix operating sys=
tem
.
Again if you want to us=
e any
flavo=
ur of
     Unix operating system you have to purchase the licence from its vendor=
so this flavours of Un=
ix
     operating system or not free of cost.
Now there is a guy call=
Linus<=
/span>
a college student deve=
loped
     a free
open source operating system
based on the core prin=
ciples
     of the Unix operating system and this operating system named as a
Linux<=
/span>
.
So again companies comi=
ng to
     picture the developed they own operating system based on LINUX operati=
ng
     system which was developed by the Linus.
OS
that are developed based on Linux=
 OS are
RHEL =
=3D=3D>
      REDHAT(IBM)
Cento=
s
it is a community OS.=
Amazon
      Linux =3D=3D> Amazon
Fedor=
a
Ubunt=
u
Like
this many flavours created from the Linux operating system those operating
systems are around
300 Plus
.
We can see these all
     different operating systems in the
AWS cloud site
(Amazon) while creating=
 the
     instances or servers.
Here for your easy
     understanding
UNIX is a grandfather
and
LINUX is a son for UNIX
<=
span
     style=3D'font-family:Calibri;font-size:11.0pt'> and
RHEL/U=
buntu/Fedora
     all these grandsons of UNIX
.
The flavours of Linux a=
lmost
     90% is same in terms of core functionalities only 10% might be differe=
nt,
     so it will be fine if your fine in any one of the operating system you=
 can
     manage rest of the flavours.
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Which OS is easy to learn? Windows/Linux OS
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
My opinion is windows
     operating system is easy to learn compared to the Linux operating syst=
em
     this is my opinion do you agree on this thing?
Yes, windows is easy to=
 learn
     compared to the Linux operating system because
Windows OS is user friendly &=
 GUI.
So that anyone I mean a=
ny
     non-technical person can easily interact with windows operating system=
.
But LINUX operating sys=
tem if
     you want to operate you have to know the commands.
If you want to create =
file
      you should know command for that.
If you want to create =
folder
      you should know the command.
In Windows you can just
      right-click & create new file we can do easily since its GUI
Because of this reason =
80% of
     the desktop users I mean in the personal systems having windows operat=
ing
     system & only 20% of machines using the Linux operating system
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
How Linux OS became very popular than windows OS=
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Now let's disc=
uss
about the next features that made very popular then windows operating syste=
m.
First one is open source operati=
ng
     system
We know that Linux is =
an
      open source operating system.
Since its open source
      operating system
You no need to purcha=
se any
       licence.
The source code that =
is
       used to develop the Linux operating system is available for free so =
any
       public user whoever having access to the internet they can read modi=
fy
       the source code and they can develop their own flavour of Linux
       operating system.
Security
In terms of security we mainly concerne=
d about
hackers
and
viruses
.
Who is
     hacker?
Hacker is a very good
      technical person on the systems with bad in tensions.
I mean he always try to
      connect to others machines and try to steal the information like
      credit/debit/bank details and any personal information & do scams=
.
Why ha=
ckers
     mostly target Windows based machines?
I don't say hackers only
     target the windows operating system and not the Linux operating system=
?
But
the chances for hacking the windows operating systems are very high compare=
d to
the Linux operating system because the number of desktop uses for the windo=
ws
operating system around 80% are there what the Linux operating system distu=
rb
only 2% so the hackers will target large number of people only instead of t=
his
number of less Linux people.
When w=
e come
     to the virus section, windows 7 having more chances to get virus attac=
ks
Why there are more chances of having virus on the
      windows machines?
How a normal install
       software on windows machines will just go to the internet and direct=
ly
       will download .exe/.msi file &b will run it as an administrator
       & will click on next-next button on the software will get instal=
led.
Suppose if the MSI are
       having virus that will affect the all the files & folders of the
       machine. Like entire C: drive & D: drive
So in this case we ha=
ve to
       reach like the machine because of the machine will become very slow
       after the virus attack.
To remove virus on sy=
stems
       re-install the OS & sometimes this might lead to data loss also =
this
       will be a huge cost to the company.
In case of Linux OS when =
we
     are installing any software we can download the software packages only
     from the official site of the respective operating system.
So there is a less chances to get=
 the
     virus affected software's or packages into the Linux systems.
Also any virus affected
     software or package installed on the Linux machine it don't spread to =
the
     all the files are folders of the Linux operating system, because of the
     file/folder permissions. So we can simply delete folder that affected =
with
     virus will resolve issue.
The ne=
xt
     feature is less resources
So
why Linux building less resources compared to the windows operating system?=
If you=
 take
     example of MP3 file and MP4 file what is the main difference between t=
his
     two files?
MP3 song audio file.
MP4 is in video + audio=
 file.
The size of the MP3 fil=
e will
     be normally around 5 MB.
The size of MP4 file ho=
w much
     it will be there it should be around 100MB
Why MP=
3 file
     size is very less compared to the MP4 file?
Because
MP3 saving only audio content but MP4 file having audio Plus video content.=
 So
this is causingMP4 file must have largest size compared to the MP3 files.
This i=
s a
     similar case for windows & Linux also.
Linux is only command line operating syste
m but
the windows is
command-line + graphical us=
er
interface
so it consumes lot of resources like CPU/RAM/HD
When you install and wi=
ndows
     operating system it will take around 80GB but when you install Linux
     operating system it will take around 5 to 10 GB.
Also the CPU utilisatio=
n will
     be very high in windows machines because of the graphical user interfa=
ce
     functionalities but it won't take that much of CPU usage in the Linux
     machine.
So companies will mainl=
y look
     for less resources obviously they will go for Linux  operating
     system.
Multi =
user
     and multitasking
Before
we understand this feature let's take an example like
One user perform one ta=
sk.
At a given time single=
 user
      only can connect to machine & can perform only one action either
      create a file/folder & after this activity only user can do other
      task.
EX: DOS
One user perform multip=
le
     tasks.
At a given time single=
 user
      only can connect to machine & can perform multiple actions like
      create a file & same time listen music
EX: WIN-2008, WIN-2010=
Many user perform multi=
ple
     tasks.
At a given time multip=
le
      users can connect to machine & can perform multiple actions like
      create a file & same time listen music on their own space.
=
EX:
      Win-server-2012/2019/2022
Highly
     available
I mean the reboot time=
 for
      the Linux is very long I mean that server will run for longer run wit=
hout
      reboot, companies we can observe some of the machines not rebooted fr=
om
      two three years.
But in windows it is n=
ot
      like that so reboot will required after the patch updates or else if =
you
      action on server & it is not replicating correctly reboot will
      required.
So all this features will out satisfying the com=
pany
requirements that want to be number one position in the market.
Futures like
Open source & less
     resources - comes under expenditure & speed(CLI)
Security feature - high=
er
     quality
Longer runs without reb=
oot -
     always available
These features
making the choice of Linux on the servers instead of windows machines.
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Architecture of Linux
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Before we disc=
uss
about the architecture of Linux let's see how
windows
architecture
will be there
Let's see this
picture here
hardware is nothing but=
 our
     physical tab laptops,
on this laptops normally
     install windows operating system
On top of Windows OS shell layer w=
ill be
     there
And finally on top of t=
he
     shell layer user will be available.
So user normal=
ly
communicate with shell(user --> shell)
shell will communicate =
with
     operating system(shell --> OS)
operating system is a
     communicate with hardware(OS --> Hardware)
And similarly in revers=
e way
     we will get the response from Hard ware to OS and OS to shell & sh=
ell
     to user.
Now le=
t's
     see what is shell?
Let me open your comma=
nd
      prompt so here you can see the black screen & this black screen we
      consider as shell.
As a user I can commun=
icate
      with shell and this shell communicate with OS and OS with hardware.
Let me find out number=
 of
      folders/files present in current path, so I provided a
dir
command in the shell =
so
      this
dir
command
will reach OS &
      hardware will get response with the list of the files/folders present=
 in
      current path.
So the Linux architectu=
re
     also almost same with the windows architecture so there is a technical
     word difference between windows architecture and LINUX architecture in
     windows we call it as
OS layer
and in Linux we call it as a
kernel=
 layer
.
But there is one more
     difference between these two architecture that made Linux is faster th=
an
     the windows. That is
GUI
layer which is present on top of the shell layer.
So when you create a fo=
lder
     from the shell it will be very quick but when you create your folder f=
rom
     windows machines first we are communicating in the GUI layer and this =
GUI
     layer again communicate with SHELL layer.
So there is a third per=
son
     between the user and shell this is delaying speed like folder creation=
&=
nbsp;
&=
nbsp;
Linux-=
Day-2
10
November 2023
16:=
56
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D
Let's understand few terminologies between Windo=
ws
& Linux
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D
Tell m=
e what
     is directory?
It's a folder, sometim=
es in
      windows we call it as a folder and in Linux we can call it as a
      directory.
Don't feel they are
      different if I interchange these two words between the windows and LI=
NUX
      operating.
Similarly in windows we=
 call
     it as an
administrator
and in Linux we call it as a
root
In windows we call it a=
s a
softwa=
re
and in Linux we call i=
t as a
package
.
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D
Linux file system hierarchy
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D
What is
     meant by hierarchy?
Just take your
=
famil=
y
as an example for hie=
rarchy
In and family
<=
span
      style=3D'font-weight:bold;font-family:Calibri;font-size:11.0pt'>grand=
pa
will be there and his=
sons<=
/span>
comes under him and h=
is
      sons having some
children
.
This looks like tree
      structure right? this is what we call as a hierarchy.
Linux =
file
     system architecture also similar to the tree structure hierarchy.
Before we discuss the L=
inux
     file system hierarchy let's discussion windows file system hierarchy
     because we already aware of windows operating system.
In win=
dows
     what directories are available normally?
C: drive or D: drive
In this two drives let=
's
      talk about C: drive
Under=
 C:
      drive what are the folders will be present?
Program files
<=
/li>
Program files 32 bit<=
/span>
Windows
Users
System 32
Like this many folders=
 will
      be present and inside that folder again many files will be present.
In the similar way Linu=
x also
     all path will start with
slash (/)
/
- this slash we can c=
all it
      as a
top level root directory
.
Under this top level r=
oot
      directory there will be many other directories.
Now le=
t's
     see the directories under the top level root directory.
root
here the root directo=
ry is
       under the top level root directory. root directory is a subdirectory=
 of
       top level root directory.
Like under C: drive p=
rogram
       files folder will be there similarly under slash root directory is
       there.
No let's open the com=
mand
       prompt, the default home directory here what is there?
C:/Users/User1
When you login Linux
       machine with root user the home directly for the root user is /root.=
Home directory is a d=
efault
       directory for the user.
Like when you close t=
he
       shell are comment from and when you open the shell are come and from
       again you will directly go to the default home directory.
home
home is a
sub-d=
irectory
under the
top l=
evel
      root directory
.
The home directory is
      similar to the
c:/users
folder in the windows.
All other non-root/non=
-admin
      users of the machine having the home directories under the  /home
      directory
Just assume there is a=
 user1
      on the Linux machine so the home directory of the user one present and
      /home/user1
Once
user1=
login to the machine =
by
      default it will go to the default home directory. So the default home
      directory for the
/home/user1
boot
What is meant by booti=
ng?
Click on the power on =
button
      some process will run in background and bring windows initial desktop
      screen.
During this process wh=
at
      happened in background?
The operating system r=
elated
      files will get activated on reloaded into the Ram and will bring
      something initial desktop screen mirror whether it is a Linux or wind=
ows
      or Mac.
So the boot directory
      contains OS is related files.
If we delete the files=
 in
      boot directory the Operating System will get corrupted and you will n=
ot
      login into the machine.
etc
Suppose you are my man=
ager
      and you ask me to create you one Linux server.
I have created one lin=
er and
      inform to my manager.
Next =
my
      manager ask me like what is the configuration of the server?
What=
 I
       will tell?
It's a RHEL machine =
I mean
        ready at enterprise Linux machine.
Having 8GB of memory=
.
And I have created f=
ive
        users in this Linux machine to login.
And I have created t=
his
        machine with so & so host name.
Like this all the
     configuration details I have told to my manager.
Now re=
ad
     this configuration files will get stored?
It
will be stored under the etc directory.
/etc directory some of =
the
     files will created automatically when you launching machine.
We
can customise the files in the etc directory based on our requirement.
usr
When we install softwa=
re in
      windows machine where it will get installed? C:/PROGRAMFILES
SIMILARLY INSTALL ANY
      PACKAGES IN LINUX IT WILL GET INSTALLED UNDER SPLASH USER DIRECTORY.<=
/span>
bin
The bin folder contain=
s the
      Linux commands.
Suppose when I executi=
ve
dir
command in windows I =
get
      response with the list of files in the current directory.
And if I run some diff=
erent
      command like
bir
I will get like this
command is not present
in windows like that.=
Why l=
ike
      that you are getting error?
Because that command
       not  defined somewhere in the machine, so we are getting error.=
The commands in the b=
in
       directory can be executed by any user whether it is a root user or
       non-root user.
Don't get confused what=
 is
     the non-root user it's a user without admin privileges are root privil=
eges
     in Linux machine.
sbin
It's a directory conta=
ins
      the commands similar to the bin folder but this commands can be execu=
ted
      only by the root user and non-root cannot execute these commands.
tmp
Contains temp files
Some machines =
will
contains different directories under the /var
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D
Setup AWS account & Launch RHEL server
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D
Different ways of creating files
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D
In windows normally how=
 to
     create file?
Right-Click
+ New File
Different ways of creat=
ing
     files
cat
touch
echo
vi
Nano
Let's =
see
     how
to create a file using cat
cat
> file1.out
This
is Chaitanya
I
live in India
Ctrl+c
How to=
read
file =
using
     cat
cat
file1.out
How to=
append
data =
to
     file
cat
>> file1.out
I am Hyderabad city
Ctrl+c
How to
     create file using
touch
touch
file2.out
The
file2.out is empty file & size of file is zero
How to
     create file using
vi
editor
vi file3.out
Editor will be opened &=
amp;
     it's only read only format.
To write the data into =
file
     --> shift + I
To exit from insert mod=
e of
     file Esc
To save file with
     modification -->
:wq!
Don't save changes &=
; exit
     from file --> :q!
Go to bottom of the file
     --> G
Go to 10th line of file
     --> 10G
Create=
 file
     using nano
nano
file4.out
To save the changes, press Ctrl + O (Hold down the
     Control key and press the letter 'O'). This will prompt you to confirm=
 the
     filename. Press Enter to confirm.
To e=
xit
     nano, press Ctrl + X. If you've made changes, it will ask if you want =
to
     save them. Press Y to confirm and then press Enter.
Linux-=
Day-3
10
November 2023
18:=
16
How to=
 list
     the files in current directory
ls
How do=
 we
     create a folder in Linux machine
mkdir
dir1
Please
don't get confused when I say something like directory is nothing holder in
Linux operating system.
Now le=
t's
     see whether directory is created or not
Just
enter "ls" command it will show the directory created
How to
     create multiple folders in single command
mkdir1
file1 file2 file3 file4
How do=
 we
     differentiate between the directories and files?
Now you can see
direc=
tory
      in blue colour
and
files are in white colour
so is this differentiation enough to find which is
      directly and which is file?
For now it is okay dir=
ectory
      is in blue colour and file is in white colour so that we can easily
      identify what is directly and what is file.
But in Linux there may=
 be
      other situations some files will come in blue colour also so like the
      differentiation between directory and files based on the colours it's=
 not
      a correct way
To cle=
arly
     differentiate what is file or what is directory we can run LS command =
with
     a flag -l
ls
-l
Here -l is nothing but
     longest format of the files/directories, In this output the first
     character defines what is directory and what is file.
If the first character =
is
     "d" then it is a directory, if there is no values the first
     character then it is a file.
Hidden
     files/directories
Files/directories
are hidden from visibility called hidden files or directories.
Suppose when you open C:
     drive we can find folders like
program files
<=
/li>
users
windows …..etc
Apart from this there =
are
      some hidden files/folders are there but you don't see it by default
If you want to see tho=
se
      files/folders you have to go to the view section and view hidden items
      then only you can see the hidden folders/files.
We will see now how to =
create
     hidden folder in windows
Create a folder
=
Right-Click + Properti=
es +
      Hidden
Similarly we can do it=
 if we
      want to hidden file
In Linux we can create =
hidden
     files are directories by just prefix dot symbol before the file name or
     directory name.
touch
.dir1
touch
.file1
Now type ls command you=
 won't
     see the hidden files.
If you want to see the =
hidden
     files that are present in current directory you have to add
-a fl=
ag
to the
ls
command.
ls -a
Now
we can see hidden files and also the n=
ormal
files that are present in the current directory.
If you want to see the =
hidden=
 files
     as well as the longest format
of the files are directly and single is command we =
can
     run
ls -al
We can use multiple fla=
gs in
     the single command and get the many details based on our requirements.=
Suppose
you want to print the
longest format
of
the files & also want to see the
hidden
files
and also you want to
sort the=
 files
based on the date of creation time
ls
-alt
Create
     multiple directories side by side
mkdir
dir2 dir3 dir4
We can see that these
     directories are created or not by using
ls
-ltr
Now le=
t's
     see how to create directly inside another directory
mkdir
-p dirx/diry/dirz
You can see whether this
     dir-x is created or not? just typing "ls" command
Here you can see only d=
irx
     created.
And dir-y created under
      dir-x & dir-z created under dir-y
To see directory create=
d or
     not inside the another directory, you have to change directory to the
     directory using
cd
command
cd dirx
Now when you type the ls
     command you can find diry folder inside dirx
In the same way to check
     whether dirz is created or not we have to change the diry folder
cd
diry
ls
Now you want to go one =
step
     back from dirz folder
cd
..
Now if you want to go b=
ack
     two steps back from the current folder I can type
cd
../..
Present
you are at the home directory of the current user.
If you see the negation
     symbol that terminal then you are at the home directory of that partic=
ular
     use whatever you login
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Next command will see PWD
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
If you want to find out=
 in
     which path your cursor present you can use PWD
pwd
=3D=3D> Print working directory
So
here we can see the working directory is /root
root
directory is present under / top level directory
Under the root directory
     again many directors are presented dir1 dir2 dir3 dir4 dirx
Inside
dirx-> diry present & inside diry -> dirz
If you want to bring th=
e full
     path of the dirz directory
You
can change folder and type PWD command
You
will get the full path of dirz from top level root directory
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
COPY
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
How to=
 copy
     files in Linux
To
copy files in Linux you can use a CP command and we have to provide the sou=
rce
location & destination location
cp
<file-name> <dest-folder>
cp
file1 dir1
How to=
 copy
     and directories from one location to another location?
To
copy directory from one location to another location we can use the cp simi=
lar
to files copy,
Additionally
will use -r flag to copy directly from one location to another location
cp
-r dir1 dir2
How do=
 you
     more files from one location to another location?
cp file1 file2 file3 dir1
How to=
 move
     file from one location to another location
In
Windows OS we will use cut and paste option to copy file from one location =
to
another location
So
if I want to know file1 into the dir4
mv
file1 dir4
How to move directory
from one location to another loca=
tion
     can you use same command
mv
dirx dir1
To rename file/folder
mv
dir1 dir2
How to delete the files=
?
You
can delete the file using rm command
rm
file1
We
will get your prompt like whether you want to delete your file? You can ent=
er
Y, if you want to delete and you can enter 'N' don't want to delete.
To delete a file without
     prompt we can use
rm
-f file1
How to delete directory=
?
rmdir
dir1
Only
useful when there is no files or sub directories  inside the directory
then only we can delete the directory.
If you want to delete t=
he
     directory which is containing files or sub directories you can use the
     command like
rm
-rf dir1
How to get the full pat=
h of
     the file or directory?
Suppose
if I ask you what is the full path of the program files in windows operating
system what you will tell?
C:/program
files
If
I ask what is the full path of the Microsoft folder in windows operating sy=
stem
again what you will tell?
C:/program
files/Microsoft
In the similar way if I=
 ask
     you full path of a particular file or folder in Linux operating system=
 how
     to get I will show you now?
We just go to the dir =
or
      file location & enter pwd
Suppose I want to find=
 the
      full path of dir1 we just change the directory to the dir1 and enter =
pwd
      command.
cd
dir1
pwd
If I ask you to create =
a file
     under dirz, how can we create?
We
just go to the dirz & and run touch command with filename
cd
dirx/diry/dirz
touch
file5
This will be hardest wa=
y to
     switch to the directory and creative file so the simplest way to create
     your file in the required directly is we have to provide the full path
     before the file name that we want to create.
touch
/root/dirx/diry/dirz
Linux-=
Day-4
10
November 2023
18:=
16
grep
grep
command is to search for a particular string or pattern in your file.
unix is great os. unix is opensource. unix is fr=
ee os.
Unix linux which one you choose.
uNix is easy to learn.unix is a multiuser os.Lea=
rn
unix .unix is a powerful.
Let search for a unix&n=
bsp;
     string  present in a file or
cat
file1.out | grep unix
Normally
Linux is a case sensitive language, so if we search "unix" only t=
he
matching string lines only will get printed.
If you want to ignore t=
he
     case sensitive while searching unix, you can use the -i flag in the gr=
ep
     command.
cat
file1.out | grep -i unix
If you want to display =
the
     lines that containing unix string and also the print the line number
     before they each line, you can use -n flag.
cat
file1.out | grep -n unix
If you want to bring the
     lines that is not containing the unix word you can use the flag -v
cat
file1.out | grep -v unix
Print the lines that st=
arted
     only with the Unix string, for this we can use cap^ character before t=
he
     string during the grep command
cat
file1.out | grep ^unix
Print the lines that ha=
ving a
     Unix keyboard as part of any string.
cat
file1.out | grep unix*
If you want to search f=
or a
     multiple strings we can use a egrep command.
cat
temp.txt | egrep 'great|operating'
more
Normally how do we read
      files?,  we just simply use the cat command.
cat
file2.out
Suppose
file2.out  is a very big file so to read all the content you have to
scroll up and scroll down am I correct or not?
The more command also u=
seful
     to read your file but we can read a file page by page instead of
     displaying all the content in the screen.
more
file2.out
After running the more
     file2.out the first page of the file is getting display,
so if you want to read =
the
     new line you can press enter.
if you want to go to th=
e new
     page you can press to space.
if you want to quit the
     prompt you can press on q.
head
head command will disp=
lay
      top lines of the file.
cat
/etc/passwd | head
head
command by default display the first to 10 lines of the file
If you want to print th=
em
     first five lines of the file you can use the command like
cat
/etc/passwd | head -5
tail
tail command normally
      display them bottom lines of the file.
cat
/etc/passwd | tail
tail
command by default will display in bottom 10 lines of the file.
Suppose if you want to
     display the bottom files of the file you can use the tail command as
cat
/etc/passwd | tail -5
You can case the tail c=
ommand
     in different way also
tail
-n 10 /etc/passwd
sort
sort command will prin=
t the
      data inside your file in ascending order based on the first letter of=
 the
      line.
sort
file3.out
sort - Sort command use=
d to
     sort the lines of a file & arranges records in particular order.
cat > file.txt
abhishek
chitransh
satish
rajan
naveen
divyam
harsh
abhishek
sort file.txt
abhishek
abhishek
chitransh
satish
rajan
naveen
divyam
harsh
uniq
uniq is the tool that =
helps
      to detect the adjacent duplicate lines and deletes the duplicate line=
s.
cat kt.txt
I
love music.
I
love music.
I
love music.
I
love cricket.
I
love music.
If you want to print on=
ly
     unique lines that are present in a file, we have to use sort & uniq
     command in combination
sort
file.txt | uniq
histor=
y
If you want to see the
      commands that you have executed since you login you can simply click =
on
      history command you will get the list of the commands that we have
      executed so far.
History of commands sto=
red in
     a file called
.bash_history
file which is presented under the home directory of
     user.
hostna=
me
Every machine will hav=
e some
      name right?
That name we can call =
it as
      a hostname, if you want to find the hostname
Type
on terminal
hostname
ifconf=
ig
If you want to see the
      private-ip address of machine we can type the ifconfig command.
Here we can see lot of=
 data
      and if you want to print only the private IP address we can use hostn=
ame
      command with -i flag.
hostname -i
/etc/o=
s-release
To
find out what operating system where using we can open your file
/etc/os-release
cat
/etc/os-release
wc
cat file1.out |
wc -w
cat file2.out |wc -c
cat file2.out | wc -l<=
/span>
awk
Print the particular c=
olumns
      in a file
firstName
lastName
age
city
ID
Thomas
Shelby
30
Rio
400
Omega
Night
45
Ontario
600
Wood
Tinker
54
Lisbon
N/A
Giorgos
Georgiou
35
London
300
Timmy
Turner
32
Berlin
N/A
cat
samp.txt | awk '{print $1, $4}'
Here the default sepera=
tor
     between the columns in
/tab
If we want us different
     separator between the columns
cat
samp.txt | awk -F ':' '{print $1, $4}'
yum
How d=
o you
      install software in windows?
Just
double click on .exe/.msi file & will click on next-next
Ex:
Let's install git on windows
In Linux to install
     software/package we use yum/dnf command
Install git on Linux
yum
install git -y
Remove git package on L=
inux
yum
remove git -y
How to list packages
     available to install & already installed
yum
list
How to list packages
     installed
yum
list --installed
How to upgrade packages=
 to
     latest version
yum
upgrade git -y
Here I used -y flag to
     proceed without prompting for Yes
Linux-=
Day-5
12
November 2023
17:=
17
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Service
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
In any operating system
     whether it is Windows/Linux some of applications/services continuously
     will run in background to make sure the features are working correct.<=
/span>
Suppose if you take a w=
indows
     operating system how to check water all the services are running in the
     windows machine?
Open
servi=
ces.msc
in the run prompt
Here in the status col=
umn
      you can see the mini services are running in background.
Some services will be
      helpful to work properly our audio systems/video systems/login access
      things..etc.
Here my
audio=
system working fine b=
ecause
      of the service "
WindowsAudio
" running continiously, If I stop it I
      can't listen anything.
So far whatever the ser=
vices
     we seen like
Audio
Video
Bluetooth
CredentialManager
are
related to the system level resources.
Apart from system level
     services we have some other application related services also there li=
ke,
Database as service
Webserver as service
Application server as
      service
The process for
     stopping/starting for any service(system/application) is same.
<=
/li>
Similar as windows in L=
inux
     as well we have services.
Now let's install apache
     webserver & start as a service.
How to
     install the Apache web server on the Amazon Linux machine
yum
install httpd -y
Now
how ca=
n we
     check whether my Apache server is running or not?
Actually
there are two ways to check whether my service is upon running or not.
service
httpd status
systemctl
status httpd
The se=
rvice
     command is used in the older version of the Linux operating systems and
     systemctl is used in the latest version of the Linux operating systems=
.
Even though if you run
     service command in the latest operating system it will work correctly =
only
     but in background the service command route to the systemctl command.<=
/span>
Now you can see that the
     status of the httpd web service are Apache web service is showing as a
     stopped state.
Let's
start the Apache web service
the co=
mmand
is
service
httpd start
In future if you
upgrad=
e the
     Apache web service
versions you have to restart the service in those situations how can y=
ou
     restart the service?
service
httpd restart
How ca=
n you
     stop the service?
service
httpd stop
In place of service com=
mand
     you can always well and good to use the systemctl command based on your
     choice the latest operating systems.
Now le=
t me
     ask you a one thing if I reboot my machine will my service automatical=
ly
     in running state?
No
it will not by default the service will not run automatically on system reb=
oot.
How ca=
n you
     enable the service to run automatically when systems get rebooted?
systemctl
enable httpd
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Users and groups management
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Scenar=
io:
Company got a new proj=
ect
     and for that project company recruited different skills people.
=
So now the company rec=
ruited
      four employees
user1
user2
user3
user4
Just assume
user1<=
/span>
and
user2<=
/span>
are
develo=
pers
and
user3=
and
user4
are
Linux admin
Now when the four peopl=
e need
     access to the servers first we have to create the groups that belongs =
to
     the users
How to create a groups =
and
     Linux
groupadd
developers
groupadd
linuxadmins
We have to create the u=
sers
     under these groups
useradd
-g developers user1
useradd
-g developers user2
useradd
-g linuxadmin user3
useradd
-g linuxadmin user4
Now let's set the passw=
ord
     for this users whatever we have created.
How
to be set the password to the users for that will use passwd command
passwd
user1
passwd
user2
passwd
user3
passwd
user4
Now let's try to login =
to the
     server using the user one account.
Login to the server for the user one will failed=
, why
it is failed?
The machines that are
     provided from the AWS by default login with username and password is
     disabled.
So to enable login to t=
he
     linux server using the username and password you have to do some small
     configuration change
Open
your
/etc sshd_config
file in this =
file
password authentication was set into no so we have to make it as a then aft=
er
we have to restart the sshd.
Now let's try to login =
to the
     server again with the user1, now you are able to login to the server
     successfully. why we are able to login successfully now?
we have update at the <=
/span>
passwo=
rdauthentication
and we have
restar=
ted
     the sshd
s=
ervice
     so now any user that is present on the server can login with their
     credentials to the server without any issues.
Sudo
     privileges
Now the users that are
      present in the
developers group and LINUX admin group
both are having the <=
/span>
root/=
admin
      privileges
is
      it that correct? - yes
So now=
 if
     you have a requirement to install any packages does the users
     user1/user2/user3/user4 can able to do?
-
no
right, why no these us=
ers
     are normal users they don't have any sudo religious so they cannot abl=
e to
     do any admin kind of actions.
Now I want to provide admin access to the
     users that are present in Linux admin group for that one what we have =
to
     do?
There will be a
=
/etc/sudoers
file this configuration file need to be updated in order to provide a=
dmin
      privileges to any group or any user.
Add the Linux admin gro=
up in
     the End of file in order to get the admin privilege.
Now try to login the se=
rver
     using the users that are presented in the Linux admin group, so I am l=
ogin
     with user3 and checking whether I am having sudo access or not.
=
After login just type s=
udo su
     - see now user3 have the admin privileges, previously we were getting
     error right? This is how we provide should access to the group level.<=
/span>
Now let's see how to grant root access to=
 the
     user level.
Now login to the serve=
r with
      the user one which is presented in the developer group and check whet=
her
      we have should access or not when we type sudo su - access denied.
So now update the
     /etc/sudoers file by adding user1 now check whether user one having the
     privileges are not.
user1 ALL=3D(ALL) NOPASSWD: ALL
When
we type
sudo su -
you are able to s=
witch
root users.
Also it is not mandator=
y to
     switch root account to run the admin level commands(user/group creatio=
n,
     enable service, install packages..etc), you can just
prefix=
 sudo
     command before the command that you want to run from the non-root user=
it will get executed
     successfully same as from root privileges.
Find
Find =
all
      the files that are present in the current directory.
find
-type f
This
command will displays all the files in the current directory and also the f=
iles
that are presented in the nested directories.
Find all the directorie=
s that
     are presented in the current directory.
find
-type d
Find that files that are
     presented under the particular path.
Let's
search the files that are presented under the top level root directory.
find
/ -type f
Find the director is th=
at are
     presented under particular directory.
In
similarly we will search the director is that our present under the top lev=
el
root directory.
find
/ -type d
Find the specific file
     location under the top level root directory.
find
/ -type f -name passwd
Find the specific direc=
tory
     location under the top level root directory
find
/ -type f -name init
free -h
du -sh *
df -h
Linux-=
Day-6
14
November 2023
22:=
10
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D
Permissions management on files and directories<=
/span>
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D
Whether it is a Linux
     operating system or windows operating system
what k=
ind of
     operations will do on files?
Normally
we do
Read
Write
execute
actions
we will perform on the files is that correct or not?
-
Y=
es it is
correct
What d=
o you
     mean by read operation on the file?
Like
running cat command are command on your file and just read the content that=
 is
present inside the file that is read operation.
What is
     write operation on  file?
We
open your file using vi command and we will write some content inside that =
file
and saving that file that is an right operation and also if you open your f=
ile
and delete some content on the file and saving the file that is also that
correct or not? - yes correct
What is
     meant by execute action on the file?
In
windows directory .EXE file will be there and when we double click on the .=
EXE
file and we will install software that is an execution action.
In
the same way in Linux also there are some script files with extension .sh, =
to
run this files we need execute privilege.
Hope now you understand=
 what
     are the actions we can do on the files.
Now wi=
ll
     discuss the level of permissions on each files/folders.
what do you mean by le=
vel of
      permissions?
Level
of permissions nothing but
who is having permissions on the files
and
what kind=
 of
permissions do they have
?
In Linux we can control=
 the
     permissions on the files mainly on three levels
Owner
Group
Public
Here owner is nothing b=
ut
     creator of the file suppose if you creative file you are the owner of =
the
     file.
Group is the where the =
owner
     is belongs to.
Public nothing but all =
the
     users that have access to the Linux machine.
How do we see the permi=
ssions
     on the files or directories?
This
command already be discussed we use ls -l command which provide the longest
format of the files.
ls -l <file_name>
-rw-r--r-- 12 linuxize users 12.0K Apr  28 =
10:10
file_name
|[-][-][-]-  
[------] [---]
|
|  |  | |     
|       |
|
|  |  | |     
|       +-----------> 7. Group
|
|  |  | |      +-------------------> =
6.
Owner
|
|  |  | +--------------------------> 5. Alternate Access Metho=
d
|
|  |  +----------------------------> 4. Others Permissions
|
|  +-------------------------------> 3. Group Permissions
|
+----------------------------------> 2. Owner Permissions
+------------------------------------>
1. File Type
How to
     modify the permissions on the files?
There
are actually 2 ways to Modify the permissions
I
am going to explain only one way here now,
The syntax to change
     permissions on files
chmod <OCATAL-NUM> filename
chmod 777 filename
In
this 3-digits
1 digit - represent
     permissions related owner
2 digit - group
<=
/li>
3 digit - all users
Each action that we per=
form
     on file will have specific value
r - 4
w - 2
x -1
The permissions of the
     specific user class I mean the owner/group/public is sum of values of =
the
     permissions.
Let's =
take a
     file & modify the permissions
Provide read, write and
      execute permissions level at owner level
Read and execute permi=
ssions
      for a group
Read permissions for a=
ll
      users
To modify the permissio=
ns
     first identify 3-digit value
owner
group
public
rwx &nb=
sp;
rx &nbs=
p;
r
4+2+1
4+1
4
7
5
4
chmod
754 file1.txt
Now check the permissio=
ns
ls
-l file.txt
Now
the permissions changed as 754
Try few use cases
Provide rwx permission=
s to
      owner, group & public
Provide rw-rw-w to
      user-group-public
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
SOFTLINK Vs HARDLINK
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
SOFTLINK
In win=
dows
     how do we create shortcuts?
Here
shortcut is just pointer to original file/folder & actual size of the
shortcut is not same as original file/folder.
Similarly as windows
     shortcuts in Linux we can us softlink to create shortcuts
ln
-s <original file> <softlink>
The soft link file size=
 is
     not same as the original file & If we delete the original file soft
     link will not work.
Softlink we can create =
on
     files & directories as well.
Softlink & original=
 file
     will have different inode.
Inode is the address of=
 the
     file where exactly its store in Hard disk
To
check Inode of file/directory we can use command
ls
-li <file name>
Hardlink
Hardlink is mirrored co=
py of
     a file.
The hardlink file size =
is
     same as the original file.
We can create hardlink =
using
     command
ln
<original file> <hard link>
If we delete the origin=
al
     file still we can access the hard link file.
Hardlink & Original=
 files
     will have same inode.
We can create only hard=
link
     for the file not the directories.
Git-Da=
y-1
15
November 2023
09:=
48
What i=
s a
     version control system?
Version control system
also referred as <=
span
style=3D'font-weight:bold'>source code management
In simple words
<=
/li>
Version
control system we can call as
VCS &
Source
code management tool has
SCM
tool
Differ=
ent
     type of VCS tools
in market,
1.
GIT
2.
SVN
3.
Clear case
4.
Mercurial
Before we understand wh=
at is
     an version control system? we will discuss
what are all the problems t=
hat
     will occur them version control system
.
Scenar=
io:
Just assume you are
     developer and working in MNC IT company & your manager came to you=
 and
     told that we have new project from some
client and he gave you some inputs to s=
tart
work on that project.
So as a next step what =
you
     will do based on the inputs that you received from the manager and cli=
ent
     you started working on developing of application.
Developer will create a
     folder in his laptop & will write the code in the files.
Once the developer comp=
leted
     first version(v1) of project, developer will set up a meeting with cli=
ent
     & manager for reviewing application.
During the first versio=
n of
     application review the manager & client are not satisfied with the
     futures that are present in application. So they suggested few more
     corrections to your application & new features.
So as a next step the
     developer what will do?
Again
he will go back to his system and based on the inputs that received from the
review meeting he will correct the source code and add new other features,
correct or not?
After the completion of=
 the
     code corrections & futures development based on the review-1 meeti=
ng
     and again you are going to set one more review meeting with client and
     manager to validate V2 code.
During the  review=
-2
     meeting also there are some more changes suggested by Manager &
     Client.
So again developer what=
 he
     will do?
He
will update the code in existing folder based on the review-2 meeting input=
s.
Again developer will se=
tup
     review-3 meeting with manager & Client to review V3 application &a=
mp;
     its code.
In
this review-3 meeting manager & client said we don't need these changes
latest but i want features that presented during the review-1 meeting that =
are
fine.
Now it=
's a
     big trouble to developer, he can't go back to the exact v1 files of co=
de,
     correct or not?
correct
Why co=
rrect?
There
are so many lines of code changed & many files are added, so he can't go
back to exactly v1 code.
V3
---> V2 ----> V1
Proble=
ms
     without VCS
Overwritten the files =
&
      not having mechanism to rollback to previous changes on files.
=
Assume when multiple
      developers are working on same project, it will be very hard to find =
who
      is working on what & collaboration will be very difficult.
=
VCS wi=
ll
     resolve all these kind of issues like,
Record the changes hap=
pened
      to the files
-
What is changed
-
When it is changed
-
Who is changed
Allows to rollback to
     previous versions of files
Allows to review the la=
test
     source code files with previous versions of files.
Acts as a best collabor=
ative
     tool for developers, so it's easy to know who is working on what &
     maintain stable code.
Types of VCS
CVCS - Centralized Ver=
sion
      Control system
DVCS - Distributed Ver=
sion
      Control system
Centra=
lized
     version control system
In
centralized version control syst=
em we
      will have one central server & which contains repository.
<=
/li>
What i=
s an
     repository?
Repository
is nothing
folder which is contains source=
 code
files
& also the
metadata about=
 the
files
.
What is
     metadata about files?
Who
is modified the file, when is it modified & who modified like this
information stored.
Now let's see how CVCS =
will
     work
Assume
there are two are developers are present developer-1 & developer-2 &
these two developers are connected to centralized repository
Developer-1 connected t=
o the
     central repository & did checkout of files that he need to update.=
Now the changes made by=
 the
     developer-1 present in laptop only.
In order to make the ch=
anges
     visible to others the developer-1 should commit those changes to centr=
al
     server.
Now developer-2 able to=
 see
     the changes made by developer-1.
Proble=
ms in
     CVCS:
Single central reposit=
ory
      always developers are connecting, so if there is any network issues
      developers will sit idle.
If central server goes
      down
that's it we lost the =
code,
      if we don't have proper backup mechanism.
SVN &a=
mp;
     IBM-Clear case comes under CVCS category
Distri=
buted
     version control system(DVCS)
In DVCS the
main =
server
     contains repository
& this repository we can call it also
remote repository
.
Developers will
=
clone =
the
     copy of remote repository into laptop
& this repository called as
local
     repository
=
.
On this local repository
     developers user will perform update/commit operations to make changes
     reflect.
In order to make the ch=
anges
     visible to others developers can push changes to remote repository.
Benefi=
ts of
     DVCS are CVCS
If main server goes do=
wn
      & we can recover the repo from latest copy local repository.
Even if there is netwo=
rk
      issue developers can work on local repositories & can push the
      changes to main repo once network available.
Git co=
mes
     under DVCS category.
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
How to
     install Git on Windows
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Download .MSI way
Using choco
Insta=
ll
      choco software in windows
Set-ExecutionPolicy
Bypass -Scope Process -Force;
[System.Net.ServicePointManager]::SecurityProtocol =3D
[System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Obj=
ect
System.Net.WebClient).DownloadString('https://community.chocolatey.org/inst=
all.ps1'))
Instal=
l git
choco
install git
Check =
git is
     installed or not
git
--version
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
How to
     install Git on Linux
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
yum
install git -y
(or)
dnf
install git -y
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D
Git config
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
This command will help =
us to
     introduce ourself to Git like who is using person using it & his m=
ail
     id.
git config --global use=
r.name
     chaitanya
git
config --global user.email chaitanya.rv99@gmail.com
To check this configura=
tion
     we will run command
git
config --list
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Create a Local repository & Explain different
stages
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Imagine this is a
develo=
per-1
machine with
window=
s OS
& git already inst=
alled
     on it.
On this developer machi=
ne a
     folder called hotel-booking created by developer-1 & this directory
     will have source code files related to the project will be developed.<=
/span>
To
conver=
t this
     hotel-booking directory as a repository
we have to run "
git
     init"
command inside the
hotel-booking
directory.
After initialization of=
 the
hotel-=
booking
as a repos=
itory
     this
hotel-booking
directory will be divided into three sections logically.
Worki=
ng
      directory
Stagi=
ng
      Area
Local
      repository
Now the developer start=
ed
     working on the project and he created
file A.java in the working
     directory
=
and he
     written some code inside A.java file.
To move the file from <=
/span>
working
     directory to staging area
we can do it by running the add command.
git add A.java
In order to make sure w=
hether
     the file is staging area are in the work space we can run the
<=
span
     style=3D'font-weight:bold;font-family:Calibri;font-size:11.0pt'>git st=
atus
command.
From
this command we will come to know whether the file is in which stage.
So
now we can see the file is in staging area.
To move the file from
stagi=
ng
     area to local repository
you can use the command
commit
.
When we run commit comm=
and in
     the repository the snapshot of the changes will be taken and committed=
 .
Along with that inform=
ation you will
get like
who committed those cha=
nges
when those changes are
     committed and
commit message.
<=
/li>
Explai=
n this
     scenario practically
To check what commits present on t=
he
     repository we can run a command
git log
.
Here we can see the fir=
st
     comment we made on the repository.
40-bit SHA code
=
Mail-id of the user
User ID
Commit message.
=
Now the changes are pre=
sent
     in developer machine only & in order push the local repository into
     internet & make it visible to other developers we have to use
     repository hosting platforms.
GitHub
Azure devops
Bit bucket
GitLab
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Create
     GitHub account & empty remote repository
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Now I will show you how=
 to
     create a remote repository.
Where do we create our =
remote
     repositories? GitHub/Azure devops/Gitlab
First of all what is
GitHub=
?
GitHub
is the repository hosting platform, it means it will store all the reposito=
ries
and make those repositories available to the other developers for easily
collaboration.
People=
 might
     think git and GitHub both same. Is this correct?
No it's not correct
      statement.
Git
is a
tool
&
GitHub
is a .
repository
hosting platform
Like camera is a tool a=
nd
     Facebook or Google drive or Google photos is a hosting platform like
     GitHub.
Now le=
t's
     see how to create GitHub account.
To create GitHub accou=
nt you
      need an email id so since I already have the GitHub account I am just
      giving the random email ID.
After creating the Git=
Hub
      account the email id will receive an 8-digit passcode and we have to
      enter this password then only our account creation will get complete.=
Now le=
t's
     understand what is an project?
Under project we can c=
reate
      the number of a repositories that belongs to specific project.
=
Suppose hospitals is my
     project then the different departments like
oncology
radiology
cardiology
gastrology
and
all those things we can consider as repositories.
Now we are skipping the=
 part
     of creating the organisation as of now and we are going to create repo
     under the default organization & default organization name userid
     name.
Create
     remote repository in GitHub with same name as local repository.
=
To create repository u=
nder
      the default organisation we need to pass unique  repository name
      and
Give the description ab=
out
     the repository the description is an optional thing, but we can provide
     it.
Next we need to choose&=
nbsp;
     repository type as a public or private.
so wha=
t do
     you mean by public & private repository?
Publi=
c
repository can be
acce=
ssible
      over the internet by any person
&
If repository
<=
span
      style=3D'font-weight:bold;font-family:Calibri;font-size:11.0pt'>priva=
te
only the
spec=
ific
      people that you granted access
.
Next don't choose the
     checkbox like readme.md file & create
empty remote repository
.
Now we have an empty re=
mote
     repository in GitHub & local repository in developer-1 machine. In
     order to push changes from local repository to remote repository
     connectivity required between them.
First let's
check =
is
     there any connectivity between local repository & remote repositor=
y
git
remote -v
There
is no connectivity b/w local & remote repo's.
To setup connectivity b=
etween
     local & remote repo we need to do
git
remote add origin <github_url >
git
remote -v
Now developer-1 is read=
y to
     push the code.
git
push origin main
GitHub repo is now upda=
ted
     with local repository changes.
Git-Da=
y-2
17
November 2023
12:=
14
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Clone repo
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
To
copy =
entire
     remote repository as a local repository into developer machine
<=
span
     style=3D'font-family:Calibri;font-size:11.0pt'> can be done using git =
clone<=
/span>
command.
In two ways we can repo=
 using
https GitHub URL
SSH URL
Let's =
see
     how to clone repo using https URL
git
clone <https_github_url>
Since
our repositories are public repositories we don't need to enter user-name &=
amp;
password while cloning repositories.
If
it’s a private repository we have to enter credentials.
Now how
     clone repo using SSH
To clone repo from GitH=
ub to
     Developer machine
SSH Connection
must be established.
How to=
 setup
     SSH connection?
On the developer machi=
ne
      create ssh-key's for the user.
ssh-keygen -t rsa
Now public key & pr=
ivate
     key is generated for the user under current user home directory.
Next add the public-key=
 in
     GitHub account & don't share private key with anyone, it's like
     password.
Clone repo
git
clone <ssh url of repo>
Homework:
Try to clone repo in Linux mach=
ine
using SSH
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
PULL
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Let's assume there are =
two
     developers DEVELOPER-1 & DEVELOPER-2 are working on same GitHub
     repository & master branch having 3-commits.
Now DEVELOPER-1 &
     DEVELOPER-2 are cloned repositories made few changes in code &
     committed in Local repository.
Now DEVELOPER-1 pushed =
the
     code into GITHUB repo & this got successful.
In the=
 same
     way If DEVELOPER-2 want to push the code into GITHUB it will get faile=
d.
     Why its failed?
Because
when DEVELOPER-2 cloned repository it was in V3 & this version updated =
to
V4 by DEVELOPER-1.
Now
DEVELOPER-2 can only update the V4 & not the V3.
To fix the issue first DEVELOPER-2=
 has to
     pull the latest changes of remote master branch in GitHub repo &
     integrate into DEVELOPER-2 master branch in local repo & after tha=
t he
     need to push it.
Let's see this practica=
lly
GitHub
      repo:
Wit=
h 3
      commits
Clone =
repo
DEVELOPER-1:
git clone
     <repo>
DEVELOPER-2:
git clone <repo>
Push c=
ode
DEVELOPER-1:
git
add file1.java
git
commit -m "Adding file1 by dev-1"
git
push origin master
DEVELOPER-2:
git push will be failed
git
add file2.java
git
commit -m "Adding file2 by dev-2"
git
push origin master
Pull t=
he
     code
DEVELOPER-2:
git pull origin master
git push origin master
Git-Da=
y-3
19
November 2023
11:=
52
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Branch
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Normally when you creat=
e a
     repository by default master/main branch will be get created inside the
     repository.
The master branch will
     contains stable & production ready code for deployments. We should=
n't
     tamper this code at all.
Suppose if we allow
     developers for directly pushing the code on master branch there will b=
e a
     chance of disturb the production ready/stable code on main branch.
so if the code on main =
branch
     is not stable then the deployments also will not work correctly.
To overcome such kind of
     issues,  Whenever developers want to work on new feature
Git allows to create a new branch=
 &
     on this new branch developers can parallel work without disturbing the
     main line branch code. Once the feature development completed feature
     branch will merged to master.
Now let's work on these
     branching practically,
Clone pets clinic repo=
By default present we a=
re in
     master branch & its having 3 files.
Create new branch calle=
d
featur=
e-1
git branch feature-1
Switch to new branch
git checkout feature-1
Check on which branch
     currently you are in
git branch
List all the branches p=
resent
     in local repository & remote repository
git branch --all
Let's add a new file &a=
mp;
     create commit, now feature branch having 4-commits & master having
     3-commits
Let's merge the feature
     branch into master
git checkout master
git merge feature
Delete the feature bran=
ch
git branch -D feature-1
Did you
     notice one issue here? while merging the code from feature branch into
     master branch
Also
devel=
opers
      are directly not allowed to push the code from local repository master
      branch to remote repository master branch
.
Code =
is not
      reviewed
by other developer=
s/lead
since the changes are
      present in Local machine.
Now we will see how to
     overcome above two issues.
How to
     protect master branch on GitHub from direct code push from developers.=
To protect main branch=
 from
      direct push, we have to setup protection policies
Repo
--> Settings --> Branches
Require a pull request =
before
     merging
--> Users can't do
     direct push & only pull request is the way to merge code to master=
.
Require
approvals
--> The code must be
reviewed & approved by other developers.
Do
not allow bypassing the above settings
--> No one have possibility to skip rules like above
Lock
--> Whenever code freeze is there, we can lock the branch. So users can't
merge pull requests.
Now next fix the other =
issue
     by raising pull request
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
GIT PULL REQUEST
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Git pull request will h=
elp us
     show the difference between personal branch & mainline branch. This
     will helps the peer developers to review changes.
Also provide feasibilit=
y to
     suggest comment on the code developed if any modifications needed.
Now let's assume
This is a developer mac=
hine
     & this is a GitHub repo with master branch
If developer wants to w=
ork on
     new feature,
he will create a
     branch called feature-1 in local repository.
Once feature development
     completed, developer will push the feature branch into GitHub repo.
Now In order to merge t=
he
     feature branch into master in GitHub, pull request need to be raised.<=
/span>
Once the pull request r=
aised
     it can be reviewed by other developers & can be merged into master=
.
Let's do this practical=
ly
     now.
Clone =
repo
git
clone
ht=
tps://github.com/chaitanyaredd/pull-request-demo.git
Create=
 a
     feature branch
in local repository based out of master branch
git
checkout -b feature1
Add ne=
w file
     & commit in feature1 branch
echo
"This is file1" > file1.out
git
add .
git
commit -m "Adding first file"
Push the feature1 branc=
h to
     GitHub
git
push origin feature1
Raise =
PR
in GitHub
Review the PR by anoth=
er
      developer(student).
Make sure the new developer must =
have
      collaborator access(settings --> Collaborator).
Merge the Pull request =
to
     master branch.
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D
Git Fetch
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D
Before we discuss on Git
     Fetch command let's discuss what are all the different branches we hav=
e in
     GIT.
In Git mainly we have t=
hree
     kind of branches
Local branch
Remote branch &
Remote tracking branch=
What is
     local branch?
The
branch that we have created in the
local
repository
& local repository presented in our laptop
What is
     remote branch?
The
branch that we created in the
GitHub
that
is called as a remote branch.
What is remote tracking
     branch?
It's =
local
      copy of the remote branch.
How can we see the rem=
ote
      tracking branches?
git
branch -r
Git
Fetch<=
/span>
command will
downlo=
ad the
     changes from the remote branch
and
updates its corresponding remote tracking br=
anch
.
In this case the change=
s are
     downloaded from remote repository to local repository but not merged it
     with the local repository branch.
Now le=
t's
     see scenario practically
Create a repository in=
 a
      GitHub with three commits in master branch and clone that repository =
into
      the local machine.
Now we have two reposit=
ories
     one is local repository and another one is remote repository in GitHub=
.
Now list the branches, =
git
     branch -a
Here
we can see the local branch as master &
=
remote
tracking branch as origin/master &
remote branch as master that is =
present in
the GitHub
Now let's make some cha=
nges
     in the master branch GitHub.
Next
step if you run git fetch command=
 the
     changes whatever present in master branch of GitHub will download it to
     them remote tracking branch in the local repository.
Can we see the changes =
that
     we have downloaded?
No
we cannot see those changes that we have downloaded into local repository f=
rom
master local  branch.
cat filename
See
no changes are coming.
Normally we should not =
edit
     the remote tracking branches.
To make visible the cha=
nges
     that are presented in the remote tracking branches to your local branc=
h we
     have to run git merge command
git merge origin/master.
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D
GIT PULL
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D
Git pull command is
     combination of
fetch
as well as the
merge
command.
It means that whenever
     developer runs the fetch command changes are downloaded from remote
     branch(master) to remote tracking branch(origin/master) & then aft=
er
     remote tracking branch will get merged to local branch.
Now let's see this scen=
ario
     practical
Update the remote repo=
sitory
      with the few commits.
Run git pull command on
     master branch
git pull origin master
cat filename
See
we can see the changes.
Dismiss stale pull request approvals
Even last approved request get dismissed whenever new com=
mit
happens on this PR.
Require review from code owners:
Post approval on PR, if any new commit triggered on perso=
nal
branch it will become as below screenshot & asks for approval latest
changes keeping previous changes approved with affecting.
CODEOWNERS
file a=
dded
at root folder & these people are reviewing code before merging into ma=
ster
branch
Git-Da=
y-4
21
November 2023
12:=
50
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Merge con=
flict
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
When same file=
 &
same line getting modified & merged into main branches one after one.
1. Git on
Windows
=3D=3D> developer1
=3D=3D> update user config
=3D=3D> feature1
2. Git on EC2 =
=3D=3D>
developer2 =3D=3D> update user config
=3D=3D> feature2
3. Merge featu=
re1
into main branch by developer1
4. Merge featu=
re2
branch into main branch by developer2
5. Merge confl=
ict
Get
the base branch changes into local machines
git
pull origin main
git
checkout feature2
git
merge master
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Forking repo
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Before we understand wh=
at is
     and Forking repository, let see this diagram
Assume=
 there
     is a repository in the GitHub & you want copy of this repository in
     your local machine how can we do that?
We
can use git
clone
command to copy
repository from the GitHub to your local machine.
Simila=
r way
     your repository in GitHub account-1 & you want to create copy the
     repository in another GitHub account-2, how can you do that?
Fork
option will be used.
When you do the fork
     repository we have two independent repos so the changes in one repo&nb=
sp;
     will not affect the another repository.
Why do=
 we
     need to fork repository?
Suppose you have inter=
est to
develop
      a hotel-booking
so you have one option like you have to write a from the scratch and
      complete the application development that is one way.
Else we can check inter=
net is
     there anyone having similar interest to develop a hotel-booking
     application & pushed code in GitHub.
So now you can take tha=
t copy
     of code into your account and you can start developing your application
     according to your company requirements using the Fork option.
When you do the fork
     repository we have two independent repos so the changes in one repo&nb=
sp;
     will not affect the another repository.
Now let's go to the Git=
Hub
     repositories, here you can see there are many number of users forked t=
his
     repository because other users considered my repositories are might us=
eful
     for them and they want to maintain my repository
in their account that's why they =
did the
     fork.
Similarly I can create =
the
     others repositories is whatever present in the different type of accou=
nt
     into my data account by clicking on the fork button.
Now here we can see the=
 owner
     of the repo is different user now when I click on the fork button it is
     coming under my own account and also by default we are copying the mas=
ter
     branch code.
The fork button you can=
 see
     the number of users have made the forking of repository on this main
     repository.
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
REVERT Changes
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Now we will see how to =
revert
     the changes from the
working area
staging area
local repository in the
      developers machine.
Now let's see how to
rollba=
ck
     changes in workspace area
In
order to revert changes from the working directory we can use a command
git restore filename
How to
revert=
 the
     changes from the staging area to working directory
git restore --staged file
#Discard change=
s from
staging area
git
restore file #Discard changes from working directory
DISCAR=
D THE
     CHANGES FROM LOCAL REPOSITORY
git
reset HEAD~ # Revert the changes from local repo  to working directory=
git
restore file
Revert=
 the
     changes from the remote repository
We
don't have any direct to it to reward the changes from remote repository.
We
have to undo the changes by comparing the last to commits and push back tho=
se
changes whatever you did again in order to under the changes in remote
repository.
.gitignor=
e
Maven-=
Day-1
21
November 2023
14:=
29
Today our topic is on <=
/span>
BUILD =
TOOL
Why do we need Build tool?
Build tool used to con=
vert
      the source code files into binary packages.
Suppose
you are a java developer, you write a code in .java files & push the co=
de
into GitHub. The source later converted into binaries packages like
.jar
.war
.ear
Which =
build
     tool used to convert the .java source code files into .jar/.war/.ear
     binaries?
maven
These binary files only=
 we
     deploy into our DEV/QA/PROD environments.
Same way if you are .Net developer, you write code in .cs files & push =
the
code to GithHub. These sources code will be converted into binaries like
.msi
.exe
.dll
Which =
build
     tool used to convert the .cs source code files into .msi/.exe binaries=
?
msbuild
Like this different bui=
ld
     tools based on the different technologies
Android --> Gradle<=
/span>
Nodejs --> npm
In this course we talk =
about
     maven as build tool since we have most of applications on Java
=
How to
     Install maven on Linux machine
Install
     java-11
List java-11 related
      packages are available
yum
list | grep -i java-11*
Install the java-11
yum
install java-11* -y
Check the java version<=
/span>
java
-version
Downlo=
ad the
     maven binary
Go to maven official s=
ite
      & get latest maven installer link
wget
https://dlcdn.apache.org/maven/maven-3/3.9.5/binaries/apa=
che-maven-3.9.5-bin.tar.gz
Extract the maven binar=
y
tar
-xzvf apache-maven-3.9.5-bin.tar.gz
Move the extracted maven
     folder as /opt/maven
mv
apache-maven-3.9.5 /opt/maven
Set the environment var=
iables
maven_home
&
path at
     user-level
Update the
maven=
_home
in ~/.bashrc or
      ~/.bashprofile
export maven_home=3D/opt/maven
Update the
PATH
variable
export PATH=3D$PATH:$maven_home/bin
(OR)
Set the environment var=
iables
maven_home
&
path at
     system-level
Update the
maven=
_home
      in /etc/profile
export maven_home=3D/opt/maven
Update the
PATH
variable
export PATH=3D$PATH:$maven_home/bin
Check =
the
     installed maven version
mvn
--version
How to
     Install maven on Windows machine - Home work
Install
     jdk-20
Download:
https://download.oracle.com/java/21/latest/jdk-21_windows-x64_bin.ex=
e
Update:
JAVA_HOME & PATH System variables
Download & extract =
maven
     binary
https://dlcdn.apache.org/maven/maven-3/3.9.5/binaries/apache=
-maven-3.9.5-bin.zip
Extract
to C:\maven
Update the MAVEN_HOME &=
amp;
     PATH variables at system level
Maven is not only a
build=
 tool
but it is also
<=
span
     style=3D'font-weight:bold;font-family:Calibri;font-size:11.0pt'> proje=
ct
     management tool
.
What is project manage=
ment
      tool?
It's used to create p=
roject
       structure.
Just check any java pro=
jects
     in GitHub, they proper directory structure.
Let me do search of ja=
va
      project in GitHub
If you see calculator
      repository, it's having proper directory structure src/main/com,
      src/main/test
If you see one more on=
line
      book store repository, It's also having directory structure in proper=
 way
To create this directory
     structure manually it's
Time taking process
Chances for not creati=
ng
      project correctly
This problems can be av=
oided
     with help maven.
Now wh=
o will
     use maven as project management tool?
DEVELOPER
DEVELOPER
- Will create project structure & will push into GitHub.
So DEVELOPERS will use =
the
     maven as
project
     management tool (To create projects) & Build Tools(To compile the
     files & generate binaries locally)
Now let's work on maven=
 as a
     project management tool practically
Assume you are java
      developer & have requirement to create application for
sdbba=
nk
in java.
DEVELOPER will create
     hotel-booking project structure using maven
open cmd & run the
      command
mvn archetype:generate
It will display list of
     templates available & prompt for template number to enter
Each template will use=
d for
      different purpose & creates different structure
Developers are respons=
ible
      to choose correct number
As of now we
go with default one & which =
is
      sample maven project.
Now the template also w=
ill
     different versions, because in background maven team continiously
     enhancing this templates. We will choose latest one.
Groupi=
d
: Normally sdbbank webs=
ite
     url is like
www.sdbbank.com
<=
/a>
In
this the groupid is
com.sdbbank
Similarly
for
www.facebook.com
the groupid is=
com.facebook
Artifa=
ctid
: What kind of operatio=
ns
     banks will do?
Net banking
Cards
Loans
Stocks
Out
of these areas we can take anyone as an artifactId
Versio=
n
: we can choose as snap=
shot
     since our project is on development phase.
Packag=
e
we can as groupid.arti=
factid
Now the project created=
 with
     name netbanking.
Let's check the directo=
ry
     structure
Install tree command &=
amp;
      check directory structure
yum
install tree -y
tree
Here we can see
=
pom.xml
src/main/java/com/sdbba=
nk/netbanking/App.java
src/test/java/com/sdbba=
nk/netbanking/AppTest.java
The files that are comes
     under the src/main
--> Re=
lated
     to functional code
What is functional cod=
e?
The
code written to develop the net banking application.
The files that comes un=
der
     the src/test --> Test code in order to validate the functional code.
     This code we can call as Unit Test code.
Why here developers are
     writing test code? Normally QA has to do testing correct?
Basic
level of functional code can be validated instead of checking with QA
engineers.
pom.xm=
l
Core configuration fil=
e of
     the maven project & it's considered as heart of the java project. =
groupId
artifactId
version
proper=
ties:
Properties section use=
d to
defi=
ne
      parameters & reuse those parameters throughout the pom.xml file
<=
java.version>1.7</java.version>
<maven.compiler.sour=
ce>${java.version}<\maven.compiler.source>
<maven.compiler.target>${java.version}<\maven.compiler.targe=
t>
Normally we can install
     java7/java8/java11/java17 versions in same machine.
Whenever developer writ=
e java
     files we have to tell maven, based on what java version source code fi=
les
     are developed.
Here with these two
     parameters maven compiler will treat,
consider the source co=
de is
      developed based on java7
Generated byte code by=
te
      code compatible with Java7
Depend=
encies:
Depen=
dencies
      are
exter=
nal
      modules/libraries that you are project depends.
Here junit dependency =
used
      to run the unit test on functional code during build process.
<=
/li>
<d=
ependencies>
<dependency>
<groupId>junit</groupId>
<artifactId>junit</artifactId>
<version>4.11</version>
<scope>test</scope>
</dependency>
</dependencies>
We can get above snippe=
ts by
     looking the maven official sites.
Plugin=
s
Plugins will provide
      additional functionalities to enable tasks compile the code, test,
      package & deploy as part of Maven build Lifecycle.
I will explain Maven bu=
ild
     Lifecycle in sometime & later you will come to know these plugin
     needed.
Hope you are clear about
     maven project directory structure.
Maven-=
Day-2
23
November 2023
18:=
38
Now the we have code r=
eady
      & pushed into GitHub
Will=
 you
       deploy the source code that is available in GitHub as it is in
       DEV/QA/PROD environments?
No
We have to convert the
      source code into binary package. How you do it?
Go
 to the repo & run command
mvn install
=
This command will
Downl=
oad
      required dependencies from internet - Without maven it will be very
      difficult to download libaries
Gener=
ate
      binary file (.jar)
Now one more directory=
 got
      created called
'target'
Here
      functional code related .class files we can see
Also =
we can
      see unit test code related .class files
jar f=
ile
      created based out of .class files
The generated .jar we =
will
      deploy into dev/qa/prod Tomcat/Kubernetes/Cloud foundry environments.=
Let's understand
MAVEN=
 Build
      Lifecycle
In Maven, the build p=
rocess
       organized in series of well-defined phases & the sequence of the=
se
       phases referred as Build Lifecycle.
If you see above diagr=
am
      there are multiple phases in build process in sequence to generate &a=
mp;
      deploy the binaries.
Let's discuss how each=
 phase
      will help
Validate -
Its
 primary purpose is to validate the project is correct and all necessary
 information is available for a successful build like the references in pom=
.xml
 are valid values or not.
This
 phase is often used to check whether the project's configuration files are
 correct and all necessary resources like dependencies are available
Ex:
 If I change dependency from log4j to log4jx the mvn validate will failed,
 because the reference log4jx not present anywhere maven repos like
 central/local/remote
mvn
 validate
Check
 the directory structure created correctly or not.
Compile - Convert the =
.java
      files into .class files & we can see these files in target folder=
mvn
 compile
Here
 in target folder we can .java files are converted into .class files
Package - Will generat=
e the
      binary file .jar based out of .class files
mvn
 package
Here
 in target folder we can see .jar file
Verify - Verify that t=
he
      project is valid and meets the quality standards, Code coverage shoul=
d be
      > 80%
mvn
 verify
Suppose if you are a
      developer & wrote 100 java files for functionality but written on=
ly 2
      java files for unit test.
Which means only 2% of=
 code
      is tested at developer side.
We can restrict the
      developers by making build failed until they wrote test code more than
      80% by using
Jacoco
plugin in pom.xml
Install - Copy the gen=
erated
      .jar file from target folder to local repository(~/.m2).
Deploy - It copies the
      packaged .jar file to the remote repository for sharing it with other
      developers
Along with these goals=
 we
      can use clean command like
mvn
 clean install
Clean
 - Will delete the target folder before fresh build process started.
Next we will understand
      types of repositories in maven, so we will come to know install &
      deploy commands clearly.
In maven we mainly 3 -=
 Kind
      of repositories,
Local
       repository
Cent=
ral
       repository
Remo=
te
       repository
Whenever developers ru=
n any
      maven command like(mvn install/deploy) maven connects to maven central
      repository which is present in Internet & downloads the required
      binaries into ~/.m2 folder on the machine to complete build process.<=
/span>
The binaries are copied
      remote repository to local repository only at first time & next t=
ime
      onwards maven will consumes the dependencies from local repositories =
from
      local repository.
Let's remove the files=
 are
      downloaded in local maven repo & run
mvn install
command
Here
 we can see binaries are downloaded from maven central repo to the local
 repository.
Now again run
<=
span
      style=3D'font-weight:bold;font-family:Calibri;font-size:11.0pt'>mvn i=
nstall
command, this time see
      binaries are downloading & it's getting consuming from the local
      repository.
Some organizations wil=
l not
      allow to connect the maven central repository & download binaries=
.
In
 these situations maven will connect to remote repositories that are create=
 in
 the organization level.
Maven re=
mote
 repository is in sync with the central repository.
Normally we tell maven=
 where
      to download binaries either from central/remote repo based on
      configurations in settings.xml(%MAVEN_HOME% /conf/)
<mirrors>
=
<!--
 mirror
|
 Specifies a repository mirror site to use instead of a given repository. T=
he
 repository that this mirror serves.
-->
<mirror>
<id>central</id>
<url>https://repo.maven.apache.org/maven2</url>
<=
/p>
<mirrorOf>central</mirrorOf>
</mirror>
=
<!-- ...
 other mirrors ... -->
</mirrors>
If
 we don;'t have above configufration in settings.xml by default we are using
 central repo for downloading binaries.
If we want to download binaries f=
rom
      custom-central repo url
<mirror>
<id>
central=
-custom
</id>
<url>
custom=
-https-url
</url>
<mirrorOf>
c=
entral
</mirrorOf>
</mirror>
<mirrorOf>:
 Specifies which repository or group of repositories this mirror should
 replace. In this case, it's set to "central," indicating that it=
's a
 mirror for the Maven Central Repository.
mvn deploy explain practically during Jf=
rog
      setup. - Try this during Jfrog session
Setup maven
      repository in Jfrog
Configure
      Deployment in pom.xml: In your project's pom.xml file, you need to
      configure the distribution management section to specify the URL and
      authentication details for the remote repository. Here's an
      example:
<distributionManagement>
<repository&g=
t;
<id>your-repo-id</id>
<url&=
gt;https://your.repository.url/releases</url>
</repository&=
gt;
<snapshotRepository>
<id>your-snapshot-repo-id</id>
<url>https://your.repository.url/snapshots</url>
</snapshotRepository>
</distributionManagement>
Replace
      your-repo-id,
https://your.repository.url/releases
,
      your-snapshot-repo-id, and
https:=
//your.repository.url/snapshots
with your
      repository details. Make sure to use the correct URL for release and
      snapshot repositories.
Configure
      Authentication: Maven needs authentication details to deploy artifact=
s.
      You can configure these details in the settings.xml file, which is
      typically located in the <Maven_Home>/conf directory.
      Alternatively, you can configure authentication directly in the pom.x=
ml
      file (although this is less secure):
<servers>
<server>
<id>your-repo-id</id>
<username>your-username</username>
<password>your-password</password>
</server><=
br>
<server>
<id>your-snapshot-repo-id</id>
<username>your-username</username>
<password>your-password</password>
</server><=
br>
            </servers>
Replace
      your-repo-id, your-username, and your-password with your repository a=
nd
      authentication details.
Run mvn deplo=
y:
      Now, you can run the following command in your project's root directo=
ry
      to deploy the artifacts:
mvn deploy
Maven
      will compile your project, run tests, and if successful, deploy the
      artifacts to the specified remote repository.
Home-work
Download the
      binaries from custom central maven repository
Build any java applica=
tion
      & generate binaries & automatically copy it to local reposito=
ry
      on fresh ec2 machine
Explain the Maven Build
      Lifecycle.
Explain =
the
      difference between a Maven Snapshot and a Release.
A Maven Snapshot is a
       version of a project under development, typically not intended for
       release. A Release is a stable version of a project that is consider=
ed
       ready for production use.
Deploy artifacts to re=
mote
      repositories
Explain Maven
      life-cycle
Explain with
      scenario how plugins downloaded from the Jfrog remote repositories
Install Jenki=
ns
Install Git &=
amp;
      Maven on server
Integrate Git with Jenkinsfile
Integrate Mav=
en
      with jenkins
Create maven
      project
Create pipeli=
ne
      project
Execute the
      pipeline
Sonarq=
ube-Day-1
28
November 2023
17:=
36
Sonarqube-1
In this you will get
     understand
What is sonarqube?
Why do we need Sonarqub=
e?
How to setup sonarqube =
on
     Linux server?
Sonarqube is
Static=
 code
     analysis tool.
Why do=
 we
     need Static code analysis tool?
Before
we understand what is Sonarqube let's jump into the development phase of the
project
During project developm=
ent
     the developer will write a code, once the code development of completed
     this code has to be reviewed by the another peer developer like Team
     lead/Architect of the project.
So now what Team
     Lead/Architect will check the code & try to identify,
Is it containing any bu=
gs?
Is it secure issues?
It means that any pass=
words
      or personal email ids are mentioned in the source code?
Is there any duplication
     code?
There might be situati=
on
      developers has to write
same piece of code in many locations of the
      files related to project
.
Using same lines of cod=
e at
     many files can be called as duplication of code.
Archit=
ect
will check possibility
     of
creating function for same
     piece of code at one location & will call that code rest of the pl=
aces
.
Is that code tested pro=
perly
     or not?
As we know
devel=
oper
      job is not only writing code for the functionality of the application=
 but
      also they have to write test code to check the functionality
.
This test code called as
=
UNIT =
TEST
Code.
So Architect will check=
 will
     the code sufficient UNIT TEST code
or not?
Is there any complex co=
de
     written?
As an architect/team-l=
ead if
      there is any complex code, you have to find-out is there any better w=
ay
      of rewriting the coding easiest way of understanding without affecting
      functionality.
Easy to integrate with
     another developers code?
Architect will review =
the
      code and check if that code is easy to integrate or not with the anot=
her
      developers code when he is working in a group of team.
All this actions are do=
ing
     manually by the people like Architect/Team Lead, so every time whenever
     developer pushed/check-in latest code this review process will come in=
to
     picture & it will kill the time of developers.
We can automate all the=
se
     actions with
static code ana=
lysis
     tool came into picture.
We have so many
=
static=
 code
     analysis tools in the market
Sonarqube
Coverity
Codescene
Veracode
Apart from these static
     analysis tools why most of the companies are choosing sonarqube?
Sonarqube is not only =
stati=
c code
      analysis but it is also a code quality management tool
.
Just assume you are a j=
ava
     developer & you have a requirement to
develop a calculator
application for mobile
     phones.
So developer what you w=
ill do
     you write a code for functionality development like,
addition
subtraction
multiplication and
division,  correc=
t or
      not? - Correct
As a developer you are not only taking =
care of
the functionality development but you also have to write a code to test your
functionalities, this
code =
called as
unit testing.
Sonarq=
ube
as a code quality mana=
gement
     tool it will
provide the unit test code reports
of your project.
Even Sonarqube will pro=
vide
     the details about
code coverage
.
What is an code coverage?
Suppose as a developer =
you
     wrote a hundred functions to complete your application development so =
out
     of those hundred functions how many functions are successfully tested
     based on that this code coverage will be calculated the projects.
The projects which are =
having
     the more coverage those projects will be considered as stable projects=
.
So all these information
     whatever we have discussed so far like
Rules<=
/span>
Rules are nothing but =
the
      guidelines/best practices that developers has to follow during the co=
de
      development.
Whenever we install son=
arqube
     server by default we get rules for each programming language that
     developer has to follow while writing code.
If there is
any
     deviation in the code for the rules defined
it will be considered as a
bug/vu=
lnerability/code
     smell
&
     displayed in the sonarqube dashboard.
Databa=
se
Once the rules are exe=
cuted
      successfully & it will generate the analysis reports.
The analysis report whi=
ch is
     created based on the sonarqube rules triggered on source code of the
     developer.
Web
     component
It will display the an=
alysis
      report that is stored in the database in nice graphical interface.
Sonarqube  supports
     almost
27 plus programming languages
and generates analysis
     reports.
How
     communication established between sonar-scanner & sonarqube-server=
,
How to
     install sonarqube server with inbuilt database
Let's discuss the
     pre-requisites to install Sonarqube server
Perquisites:
JAVA
Why we=
 need
     Java as it request it to install sonarqube?
Because
Sonarqube is developed based on Java programming language.
To install Java on Linux
     machine we have to run a command like
yum install java-17* -y (sonarqube LTS 9.9.3)
Sonarqube provides LTS(=
Long
     Term stable) sonarqube-server products & latest release
     sonarqube-server products.
LTS means its stable v=
ersion
      of product & if its containing any bugs/vulnerabilities in feature
      you can get fixes for those without being impacted with other
      functionalities.
Latest products contin=
uous
      improvements for the product & can't guarantee on few of features=
.
Now to download the son=
arqube
     installer from LTS model & go to the official site of sonarqube.
There
we can find the different level of products will be available like
Community
Enterprise level
=
Cloud level
Like
this different products available.
Instal=
lation
     steps:
So in this session we =
are
      going to install the community edition.
https://binaries.sonarsource.com/Distribution/sonarqube/son=
arqube-9.9.3.79811.zip
Extrac=
t the
     zip file
unzip
      sonarqube-9.9.3.79811.zip
mv sonarqube-9.9.3.798=
11
      /opt/sonarqube
Create sonar user
useradd
sonar
Change ownership of
     /opt/sonarqube to sonar
chown
-R sonar:sonar /opt/sonarqube
Start sonarqube as non-=
root
     user
cd
/opt/sonarqube/bin/
./sonar.sh
start
Now access the sonarqub=
e in
     browser
http://<ip-address&g=
t;:9000
Username:
admin
Password:
admin
How to
     install sonar-scanner
Download sonar-scanner=
https://binaries.sonarsource.com/Distr=
ibution/sonar-scanner-cli/sonar-scanner-cli-5.0.1.3006-linux.zip
Extract it
unzip
sonar-scanner-cli-5.0.1.3006-linux.zip
mv
sonar-scanner-cli-5.0.1.3006-linux /opt/sonar-scanner
Check sonar-scanner ver=
sion
Sonar-scanner
--version
Sonarq=
ube-Day-2
28
November 2023
23:=
20
Console
     overview of Sonarqube
Projec=
ts:
Once you logged into the console,=
 when
      you click on the projects it will be empty for the first time and her=
e we
      can create projects based on our
requirement.
This project console wi=
ll
     started getting filled up when you try to push the analysis reports of
     your source code projects.
In sonarqube we can cre=
ate
     projects in two ways,
Manually
Another one is by
      integrating sonarqube with other source code management tools like
GithHub
Gitlab
Azure devops
Bit bucket
Now let's start create a
     project manually,
To
create a project manually we have to enter owner project key & now I
gave
project
key as
calculator-dev
sonar.login
as calculator-dev
sonar.login is used to
     authenticate either from Jenkins/cmd prompt to the sonarqube.
Now we have to find out=
 the
     command that need to be executed to publish analysis reports of your
     projects into sonarqube.
Click
on continue, it will give the command to execute.
As of now I am just sav=
ing
     this command into the notepad after sometime I will show you how to
     execute this command from the command prompt.
The next tab
issues=
it will show you the l=
ist of
     the issues that are present in your source code related project as of =
now
     it will be empty since we don't have any projects.
Next r=
ules
As I said earlier rule=
s are
      best practices that each developer keep in mind while writing a code =
for
      his project.
Sonarqube supports
     almost  27  programming language.
Each programming langua=
ge
     having some set of rules
Java is having 670 rul=
es
      &
.NET having 400
Like
that each programming language having some number of rules if there is any
deviation from this rules that will be report as an bug or duplication or
vulnerability.
Next
quality
     profiles
Quality Profile is not=
hing
      but
collection of the rules & these collection of rules(quali=
ty
      profile) will be applied on code during analysis of the project.
By default each program=
ming
     language associated with
sonar-way
quality profile.
If
you see the Java related sonar-way quality profile it's having 483 rules are
active & 143 rules are inactive by default applicable to any Java relat=
ed
projects.
We can create a quality
     profiles on our own instead of default one and we can enable/disable s=
ome
     more extra rules in that quality profiles depend on the need.
Show this practically.<=
/span>
Create
java-custom-profile with 626 active rules.
UC: Now we will see practically how to
     generate static code analysis report & publish it to sonarqube.
Pre-re=
quisites
EC2 server
Git
Maven
Sonar-scanner
Sonarqube server
GitHub(java-repo):
Clone =
repo:
git
clone
http=
s://github.com/chaitanyaredd/onlinebookstore.git
Build:=
mvn
clean install
Run st=
atic
     code analysis:
mvn
sonar:sonar \
-Dsonar.projectKey=3Dcalculator
-Dsonar.projectName=3Dcalculator
-Dsonar.login=3DXXXXXXXXXXX
-Dsonar.host.url=3Dhttp://<ip-address>:9000
Now in during code anal=
ysis
     sonar-way quality profile applied on code which was containing 400+ ru=
les
     for java code & generated static code analysis report. This report=
 is
     available in sonarqube with project name calculator.
Here we can see all det=
ails
     like
Bugs
Vulnerabilities
=
Code coverage
Code duplications
Code smells
UC: Change quality profile for the
     sonar-project & new custom profile must have 600+ rules.
Modify the quality prof=
ile of
     project to custom-java-profile.
Re-run static code anal=
ysis
     on code,
mvn
sonar:sonar \
-Dsonar.projectKey=3Dcalculator
-Dsonar.projectName=3Dcalculator
-Dsonar.login=3DXXXXXXXXXXX
-Dsonar.host.url=3Dhttp://<ip-address>:9000
Now quality profile of =
the
     project modified from
sonar-way
to
custom-java-profile
Next o=
ne is
     quality gates
Quality gates are noth=
ing
      but setting threshold levels for the each measurements of project &am=
p;
      if any measurement is below that threshold level that Sonar project
      status will be should failed.
Like if project is cont=
aining
bugs more than one that
      project status should be filled.
If project would cover=
age is
      less than 80% that project status will be failed.
Let's setup quality
     gate(custom-java-gate_ instead default quality gate.
UC: Modify the quality gate of calculator
     application to custom-java-gate & make project status as failed.
Clone=
 repo:
git
clone
http=
s://github.com/chaitanyaredd/onlinebookstore.git
Build:=
mvn
clean install
Run st=
atic
     code analysis:
mvn
sonar:sonar \
-Dsonar.projectKey=3Dcalculator
-Dsonar.projectName=3Dcalculator
-Dsonar.login=3DXXXXXXXXXXX
-Dsonar.host.url=3Dhttp://<ip-address>:9000
Now the calculator proj=
ect
     status will be in failed state.
Homewo=
rk:
Repo:=
https://github.com/cha=
itanyaredd/petsclinic.git
Do the static code ana=
lysis
      on java project & publish report to sonarqube
Create custom quality
      profile & update it sonar project
Create custom quality =
gate
      & make the project as failed
Generate custom sonar.=
login
      token & use it this token during latest scan.
Jfrog-=
Day-1
29
November 2023
14:=
55
In this session we are =
going
     to talk about
what is an Artifact?
what is an Artifact
     repository?
Types of Artifact
     repositories?
Jfrog Artifactory?
How to install the JFROG
     Artifactory on ec2
First =
of all
     can you tell me what is an Artifact?
It's a binary file or p=
ackage
     which is generated after build process completed on the source code.
Suppose just assume you=
r Java
     source-code is available on the GitHub after the build process the bin=
ary
     files will get created & the format of the files like JAR/WAR/EAR
     files.
Similarly the .Net sour=
ce
     code will generate the binary files in the format like .exe/.msi
     packages after the build process gets completed.
In general the binary f=
iles
     that are created after the build process created we can refer them as
     artifacts.
So now the files like
     JAR/WAR/EAR/MSI/EXE we can call as a artifacts.
Normally whenever there=
 is a
     change in the suits that is presented in the GitHub an Artifact will g=
et
     generated.
What w=
e will
     do with this Artifact?
we
will deploy this Artifact in DEV/QA/PROD environments.
Mostly the developers w=
ill
     check-in latest code into GitHub many times in a day,
for every latest check-in made in=
to
     GitHub repository an Artifact will get generated. The Artifact whateve=
r is
     created will do deployment in to the DEV environment.
Just Imagine the applic=
ation
     was working without any issues before the deployment. But after the la=
test
     Artifact deployment application is not working correctly.
How do=
 you
     fix it?
We have to revert the
      changes in code & get the Artifact for reverted changes & dep=
loy
      it. This is one way and its time taking process.
Maintain storage for
     artifacts & deploy previous artifacts whatever needed.
Which =
way we
     will normally after in this to options obviously will go with the seco=
nd
     option only correct or not? -
Correct
Now Artifact repository=
 tool
     will help us to take a backup of artifacts that are created as part of=
 the
     build process for ever latest check-in in GitHub. So if there is a
     requirement to rollback your environment to the previous Artifact vers=
ion,
     you can simply pull that Artifact from the Artifact repository and you=
 can
     make it your application working successfully.
Artifact repository is =
not
     only used for storing the binaries but it is also  provide depend=
ence
     libraries that are required to complete build process successfully.
Normally when we run m=
vn
      commands the binaries are downloaded from internet instead of that we=
 can
      download it from Jfrog.
Now let's see this
     practically
When you run
mvn i=
nstall
command the Maven com=
mand
      connects to the central repo which is on the Internet & download =
the
      libraries that are needed to build your application.
In some organisations i=
t is
     not allowed to connect directly to the internet and download the requi=
red
     packages.
In those situations in =
order
     to get the binaries the Maven command will connect to the Jfrog
     artifactory and Jfrog will get will get in sync with the central
     repository which is stored on the internet.
In the market there are
     number of Artifact repository tools are there
Helix
Pulp
Nuget
Jfrog
Nexus
Docker registry
<=
/li>
In this set of tools we=
 are
     going to discuss about the JFROG artifactory tool.
Jfrog artifactory tool =
mainly
     available in two editions
Pro-edition
Open source solution
Now we'll see
how to
     install the open source solution model Jfrog artifactory on Amazon Lin=
ux
     ec2 machine.
Prere=
quisites
Create EC2 with insta=
nce
       type of t2.small
Allow the ports
8081
8082
Java
Maven
Git
Instal=
lation
     steps
There two types of
      installable available for Jfrog
pro installer --> =
It's
       Licensed version
oss installer --> =
It's a
       free open source solution
Login to EC2 with root =
user
     & install java
yum install java-1.8* =
-y
Download the artifactory
     installers into /opt
There
two types of installable available for Jfrog
pro installer --> It=
's
     Licensed version
OSS installer --> It=
's a
     free open source solution
Now
let's install OSS installer
cd
/opt
wget
-O
https://releases.jfrog.io/artifactory/bintray-artifactory/org/artifactory/=
oss/jfrog-artifactory-oss/6.23.42/jfrog-artifactory-oss-6.23.42.zip
Extract the archive
unzip
jfrog-artifactory-oss-6.23.42.zip
mv
jfrog-artifactory-oss-6.23.42 jfrog
set
JFROG_=
HOME
variable
echo
"export JFROG_HOME=3D/opt/jfrog" > /etc/profile.d/jfrog.sh
source
/etc/profile/jfrog.sh
Run a start-up script
cd
/opt/jfrog/app/bin/
./artifactory.sh
start
Access the artifactory =
from
     browser
http://<dnshostname>:8081
<=
/p>
Default credentials to =
login
     jfrog artifactory
user:
admin
password:
password
Change the default pass=
word
Here we can create diff=
erent
     type Artifact repositories based on the source code,
If we have
java<=
/span>
source code we can cr=
eate
maven=
repository
If we have
php
source code we can cr=
eate
php
repository
If we have
pytho=
n
source code we can cr=
eate
py
repository
If we are
not =
sure
      about the source code
we can create
Generic
repository
In Jfrog main we will have 3 types=
 of
     repositories
Local=
--> Local repositories are =
the
      place to store artifacts generated as part of build
Remote=
--> This repository get in syn=
c with
     central maven repository
Virtua=
l
--> It's a combinat=
ion of
     local + remote repositories
In
Local repositories we can see
libs-snapshot-local
libs-release-local
In
Remote repositories we can see
jcenter
In
Virtual repositories we can see
libs-snapshot
libs-release
UC: Cr=
eate a
     maven local repository with name "
online-bookstore-local
" for online-bookstore java
     application
.
This will help us to s=
tore
      different versions of artifacts like
jar
war
ear
UC: Cr=
eate
     maven remote repository with name
"jcenter"
This repository will h=
elp to
      download the dependencies from jcenter repo from Jfrog instead of the
      central repository in Internet
UC: Cr=
eate
     maven virtual repository with name
"online-bookstore"
online-bookstore-local=
 +
      jcenter
Check Artifact reposito=
ry
     browser & we don't see any artifacts on those repositories, those =
are
     empty.
Jfrog-=
Day-2
01
December 2023
17:=
09
UC1: H=
ow to
     integrate Jfrog Artifactory with maven
Pre-r=
equisites
Source code:
https://github.com/ya=
nkils/hello-world.git
Tools:
Git
Maven
Jfrog
Integr=
ation
     maven with Jfrog steps
In
order to publish the
Artifact into the jfr=
og
online-bookstore-local repository
Go to
Jfrog
online-bookstore-local
repository & setup
     =3D=3D> Deploy
Copy the <distributi=
on
     Management> XML code paste into pom.xml
Run mvn deploy {Will tr=
ies to
     deploy Artifact into
online-bookstore-local
repository}
Deploy failed due to
     authorization issue
Change the user-name &a=
mp;
     password for in ~/.m2/settings.xml(The user must have admin/write
     privileges)
mvn deploy
The
jar file along with pom.xml into Jfrog
onl=
ine-bookstore-local
repository
Why snapshot pushed to libs-snapshot-local?
due to version tag contains
1.0-SNAPSHOT
b. Publish the Artifact in=
to
jfrog release repository
A. Remove -SNAPSHOT in pom=
.xml
& run mvn deploy
B. Copy the <distributi=
on
Management> XML code of libs-release-local into pom.xml
C. Artifact will be pushed=
 into
libs-release repo
UC2: P=
ull
     the dependencies from Jfrog artifactory rather than maven central repo=
Rename the ~/.m2/setti=
ng.xml
mv
~/.m2/setting.xml ~/.m2/setting_bkp.xml
Go setup of
     "jcenter" repository in Jfrog & generate settings.xml fi=
le,
     next create ~/.m2/settings.xml file with generated content
mvn clean install
Artifacts
will be downloaded from jfrog remote repo
Rename the
     ~/.m2/setting_bkp.xml to settings.xml
mv
~/.m2/setting_bkp.xml ~/.m2/setting.xml
mvn clean install
Now
artifacts will be downloaded from central maven repository present in inter=
net.
UC3: How to integrate Jfrog Artifactory w=
ith
     Jenkins Maven project
-
Try this scenario once
Install
     "Artifactory" plug-in
Manage Jenkins -> J=
enkins
      Plugins -> available -> artifactory
Configure Artifactory =
server
      credentials
Manage Jenkins ->
      Configure System -> Artifactory
Artifactory Servers
Server
ID : Artifactory-Server
URL
: Artifactory Server URL
Username
: jenkins
Password
: jenkins@123
Create a Maven Project=
Job =
Name
: artifactory-projec=
t
Source code managemen=
t
Git URL :
https://github.com/c=
haitanyaredd/hello-world.git
Build Environment
Resolve
artifacts from Artifactory : <provide Artifactory server and repository
details>
Build
- Goals: clean install
Post-build
Actions
Deploy
Artifacts to Artifactory : <provide Artifactory server and repository
details>
Execute
job
UC4: How to download Jfrog Artifact with
     Jenkins Freestyle project-
Try this
     scenario once
Webhook
Jenkin=
s-Day-1
01
December 2023
18:=
39
Today onwards we are go=
ing to
     start discussion on the Jenkins tool.
Before we are going to
     understand
what =
is
      Jenkins tool?
Why d=
o we
      need Jenkins tool?
How to
      install Jenkins on AWS Linux EC2 instance
Jenkins is a
CI/CD=
tool
.
CI
- Continuous Integration
CD
- Continuous Delivery (or) Conti=
nuous
      Deployment
Now let's understand wh=
at
     CI/CD tool will do,
Assume there are 3 deve=
lopers
     are working in a project.
These
three developers normally will develop the code for the project in their
laptops, correct or not? - Yes
After
code development completed these developers will keep the code in common pl=
ace,
correct?
What is that common place?
GitHub
Now assume this is a Je=
nkins.
What are all other tool=
s we
     have covered so far?
I
have discussed
build tool as a Maven
Static code analysis to=
ol as
     a sonarqube
Once application develo=
pment
     code completed & you generated packages like .jar/.war/.ear file, =
will
     you deploy it to client environment directly? - No
Why?
There will be a chances for issues/bugs in that code & so whenever we
deploy that .jar/.war/.ear there will be a chances of application will not =
work
correctly.
So before we deploy
     application into client environment first we do test in DEV & QA
     environment, after the regression test completed successfully we do
     deployments in PROD environments.
Let's
assume this is
DEV environment & I=
t's
     automated testing setup
QA environment & It=
's
     automated testing setup
PROD environment &
     prod-checkouts
Now all these tools are
     integrated with Jenkins
GitHub
Maven
Sonarqube
DEV/QA/PROD servers
So whenever there is a =
Code change in a GitHu=
b
Jenkins will download t=
hat
     code and inform maven to run build command mvn clean install
& will generate packages
     .jar/.war/.ear
Once the packages are
     generated next Jenkins will inform sonarqube to run static analysis &a=
mp;
     publish generated report into sonarqube dashboard.
Now packages are deploy=
ed
     into DEV servers automatically with help of Jenkins.
For each environment t=
here
      will be a endpoint URL like
https:// <dev-server-ip>:=
8012
Next QA engineers will=
 do
      end to end testing in DEV environment.
Once the testing compl=
eted
      successfully in DEV environment QA will green signal to proceed to de=
ploy
      on QA environment.
Now Jenkins will do
     deployment to QA servers,
Now QA environment wil=
l have
      one more endpoint URL like
https:// <qa-server-ip>:8=
012
Again QA engineer will=
 do
      end to end test manually in QA environment.
Now we see there is no
      issues & ready to take prod & we have to take approval from
      product-owner to deploy application in to PROD.
After product-owner app=
roval
     application will get deployed into PROD environment with help of Jenki=
ns.
Contin=
uous
     Integration
=3D=3D> Once developer check-in code into GitHub & on that code=
Automated build
=
Automated unit-test
Automate code analysis=
Artifact will stored <=
/span>
Contin=
uous
     Delivery
=
=3D=3D>
     It's a process to automate deployment in DEV & QA environments &am=
p;
     automate testing as well for those two environments(non-prod), but we =
need
     approval of application owner to do production deployment.
Contin=
uous
     Deployment
=
=3D=3D> It's a process to auto=
mate
     deployment in DEV & QA environments & automate testing as well,
     & no need approval from application owner to do production deploym=
ent.
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
How to
     install Jenkins in EC2
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
Go to the official site:
https://jenkin=
s.io
Pre-re=
quisites
EC2 instance: Amazon-L=
inux
Allow port 8080
=
Install Java-11
yum install java-11-openjdk-devel -y
Instal=
lation
     steps
Add t=
he
      Jenkins repo to download the packages:
sudo
wget -O /etc/yum.repos.d/jenkins.repo
https://pkg.jenk=
ins.io/redhat-stable/jenkins.repo
Import=
 key
     file to authenticate the Jenkins repo
=
in-order to install the Jenkins package
sudo
rpm --import
https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key
Install Jenkins
<=
/li>
yum
install jenkins -y
Start jenkins server
systemctl
start jenkins
To
     auto restart jenkins on server reboot
systemctl enable jenkins
Configure Jenkins
By default jenkins run=
s on
      port 8080
We can access jenkins u=
sing
     URL
http://&=
lt;ip_address>:8080
Default user name for j=
enkins
     is
admin
Password for admin stor=
ed by
     default at
/var/lib/jenkins/secrets/initialAdminPassword
=
Do the installation of
     recommended plugins
Change
     password of admin user
Next
     I will show you how to create jenkins job, configure it & execute =
it.
Click
      on new-item to create job
We
      have enter the name of the job in the text box.
There
      are different kind of job types are present to create.
Free-style
Pipeline
Folder
Maven
Freestyle:
This is the most common & basic job type in Jenkins. <=
/span>
Using this job type we can process for build, test &
         deploy processes with various configurations & settings option=
s in
         GUI way.
Pipeline:
Using this option we define the process for build, test &a=
mp;
         deploy with code either in scripted type/declarative type.
<=
/li>
Folder:
This option used to organize the jobs, I mean that if you =
have
         50 jenkins-jobs, out of these 25-related to Team-A & other
         25-related to Team-B. So we can create two folders like Team-A &am=
p;
         Team-b, we can move the Team-A related jobs to Team-A folder &
         Team-B related jobs to Team-B folder.
Maven:
This option is mainly designed for build, test & deploy
         process for Java
based
         applications.
Let's
      choose the freestyle job option & continue.
Here
       what are the different sections to define process for build, test
       deploy.
General
Source
        code management
Build
        Trigger
Build
Post-build
First
       we go with basic configurations,
In
        General section under
description
we can write
the purpose of the
        job.(Like: This is my first jenkins freestyle-job)
Under
        the build section choose execute sh script & enter command to p=
rint
        message
"This is my first jenkins job"
<=
/li>
echo "This is my first jenkins job"
Why did I entered echo command? because jenkins present
         running on Linux node.
Wherever we created the jobs in jenkins, that no=
de
         we can refer as master node.
Save:
If you click on save button you remain in the sa=
me
        page & configuration are applied.
Apply:
When we click on apply if any configurations tho=
se
        will get applied & will go back jenkins main page.
Now
       Execute the job --> See the output of job execution -->
&quo=
t;This
       is my first jenkins job" got printed
This
       job triggered for only one time so far based on job history.
<=
/li>
When
       you click on execute one more time & we can find the job executi=
on
       number.
Hope
     now you got idea how to create, configure & execute the job.
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Home-work
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Create freestyle Jenkins job to print the date
Job name:
date-job
Description:
To print the date of Jenkins EC2 server
Execute shell:
echo “The date & time is: ” `date`
<=
/li>
Jenkin=
s-Day-2
04
December 2023
17:=
25
How to integrate Jenkins with GitHub
Create
       a freestyle jenkins job by clicking on New-Item =3D=3D>
onli=
ne-bookstore
Under
       source code management chose Git
Provide
        the repository URL that we are looking to clone & build the
        Artifact
Also
        mention branch name that we are looking to clone repository
<=
/li>
Mostly
        the branch name will (*\master)
Do
       we need to enter credentials?
The
        online-bookstore is a public repository, so there is no need of
        providing credentials.
If
        repository is private repository we have to enter credential's.
Apply
       =3D=3D> Execute
The
       job is got failed & If we see job execution log we can find the
       error.
Here
       what is the error? Git command not found
Go
       & install the Git jenkins server
Now
       re-execute the job, next if we check the Jenkins job log we see
       repository is cloned successfully.
How to integrate jenkins with Maven
For
       the same online-bookstore job only after cloning completed we will r=
un
       the
mvn clean install
command.
Build
       =3D=3D> Execute shell =3D=3D> mvn clean install
The
       mvn command will run at the location wherever POM.XML present, if we
       trigger it from any other location it will be failed.
The pom.xml present at top root directory of the
 repo.
Apply
      =3D=3D> Execute
Build
      will failed, why? No maven installed on server
Install
      maven on jenkins server.
Global
      Tools Configuration =3D=3D> Provide any random name =3D=3D> Ent=
er the maven
      path
So far the job online-bookstore runs only on the ma=
ster
      branch by default, now I want to run the jenkins job one time on mast=
er
      branch & other time on some different branch, how can you do that=
?
Go
       to online-bookstore =3D=3D> General =3D=3D> This project is
       parameterized
=3D=3D>
       Git-Parameter =3D=3D> Branch(parameter-name) =3D=3D> Apply
Now
       while trying to execute the job now there is no option for
Build
       & only Build with parameters
option present since this job is enabled for
       parameterized.
After
       click on the
Build with Parameters
we can see option to choose the branch na=
mes
       & these names of the branches that present in repository.
=
Creat=
e new
      job similar to (online-bookstore) another one without creating a job =
from
      scratch.
Present we have job w=
ith
       name
online-bookstore
& this will clone online-bookstore repository
       & will build it.
Now we will create ano=
ther
      job with name
pets-clinic
with the same job configurations of online-bookstor=
e
To create new job para=
meter_
      jobs
New-Item
à
pets-clinic
à
copy-from-template
<=
span
 style=3D'font-family:Wingdings'>à
online-bookstore
We can place the repository URL of pets-clinic, so =
job
      configuration completed for the pets-clinic completed with less effor=
ts.
Delet=
e job
      in Jenkins
Opti=
on1:
On job-name
<=
span
       style=3D'font-family:Wingdings;font-size:11.0pt'>à
Click on Down arrow =
à
Delete project
Option2:
Click on Job-name
à
Delete-Project
Jenkins-Dashboard:
S
à
Indicates whether job is success/failure
W
à
Sunny, It means all the builds of the jobs are successfully completed=
.
C=
loudy, it
 means few of the builds of the jobs failed.
R=
ainy,
 most of the builds completed with failed status.
Last successful build<=
/span>
Last failed build
Last Duration
<=
span
      style=3D'font-family:Wingdings;font-size:11.0pt'>à
For how long last tri=
gger
      build run to get completed.
Scheduled build job
à
Trigger it to run build for the job “First Jenki=
ns
      Job”
Build-Triggers:
So far how are we running the
       jobs?
We=
 are
       running manually correct, right? - Yes- just click on build & jo=
b is
       executing
There are different ways to execute the jobs rather
       than click on build icon,
Build the job remotely:
Provide the authentication token & copy that=
 URL
         in the separate cognito mode to run the job.
Previous the job executed x times now we can it =
got
         executed with y times.
Build periodically
We can run the job schedule basis like every day 1=
0AM
       or every one hour like that
To schedule to job fill this five * with values
*minutes
*hours
*date
*month
* year
Poll-scm
This option make the jenkins to check the GitHub
       repository based on scheduled windows & if there is any changes
       build will get triggered.
***** every minute jenkins check GitHub repository
       & if there is any changes in repository build will get triggered=
.
GithHub hook trigger for SCM
      polling:
Web
       hooks help us to notify the external services like jenkins whenever
       certain event occurs in GithHub repositories.
External
        services are nothing but Jenkins
Event
        in GitHub refers branch-creation/push to repo/merge request
<=
/li>
Suppose
       whenever developers push/check-in the latest commit into the reposit=
ory
       automatically jenkins will run.
Let
       see this scenario practically
Create a free-style =
job
Source cod=
e
https://github.com/chaitanyaredd/onlinebookstore=
.git
Invoke top level ma=
ven
         targets
à
mvn clean install<=
/span>
Choose the Build tr=
igger
         option
à
GithHub hook trigg=
er for
         Git SCM polling
Create web hook in Git=
hHub
      repository
Go to
à
=
https://github.com/chaitanyaredd/onlinebookstore.g=
it
à
<=
span
       style=3D'font-family:Calibri;font-size:11.0pt;font-weight:normal;
       font-style:normal;font-family:Calibri;font-size:11.0pt'> Settings
à
<=
span
       style=3D'font-family:Calibri;font-size:11.0pt;font-weight:normal;
       font-style:normal;font-family:Calibri;font-size:11.0pt'> Add web hoo=
k
Payload URL
https://<jenkins_url>:8080/github-webhook/
<=
/a>
Content-Type
<=
span
       style=3D'font-family:Wingdings;font-size:11.0pt'>à
Application/json
Which
       event you would like to trigger this web hook?
à
Push
Trigger other jobs
Assume there are two jobs - job1 & job2
You want job-2 run automatically after job1 finish,
       then we can use this option.
Let's try this practically
Job1 -->Trigger other job(job-2) --> Shell(=
echo
        "This is job1")
Job2 --> shell(echo "This is job2") =
Homework
Clone
       repo in jenkins from private GitHub repo
Create
       Maven job & build it
Create s=
tring
       parameterized job & print the value of that string parameter
To
        create parameterized jobs we have to choose "
This
        project is parameterized
" option we can create jenkins job.
So
        During job runs we can pass the values to parameters & can us t=
hose
        values of parameters.
During
        parameterized jobs creation we have different options,
String
Boolean
File
Password
Choose
Let's
        continue job configuration
Let's choose the string parameter
De=
scription:
to print the name =
of
         Ex-president of US
Execute shell:
Name=3D”Trump”
echo “The Ex-President of US is $Name”
Apply
Execute
      the job with option
"Build with parameters"
It
       will prompt to enter string value
We
       can provide any values as we need.
Create parameter job2:
Create choose parameterized job & print the value of that
      choose parameter
.
Pass the Name as string paramete=
r &
       Execute it
Pass
       the Name as choice parameter & Execute it
Jenkin=
s-Day-3
Today ses=
sion
we will s=
ee basic
      configurations that we need to do in Jenkins.
For that let's go to =
Manage Jenkins
è
Configure system<=
/span>
home
      directory
It represent the home
       directory of jenkins & contains the configuration details of Jen=
kins
       server like
Jobs
Plugins
Logs
Secrets ..etc
=
=
By default on Linux se=
rvers
      the jenkins home directory is
/var/lib/jenkins
Sometime if there is a=
ny
      space restriction issues we can change this home directory to differe=
nt
      location(/home/jenkins/jenkins_home).
System
      Message
What is System Messag=
e?
The message whatever=
 we
        give in this text box it will be displayed on Jenkins console page.=
Let me put message here
      “This is used of DEVOPS Training”.
Now we can see some me=
ssage
      on Jenkins console.
We write the system me=
ssage
      in html format, So we can get the message in correct font on jenkins
      console page.
<h1> This is used of DEVOPS Training </h1>
Preview
Apply
Check in Console
If you are not able to=
 use
      the html
Go to Configure Global
       Security
à
Markup Language
à
choose safe html
No. of
      Executors
It indicates
how=
 many
       number of parallel jobs can run at same time
.
Assume there are 10 jo=
bs
      & if we trigger these 10 jobs at same time only 2 two jobs will
      executed & after that other 2 jobs will get executed.
=
Quiet
      Period
No. of seconds, that
       Jenkins will wait to trigger the job.
Why Jenkins will wait =
this
      many seconds to trigger job?
Normally Jenkins job =
will
       get run on scheduled basis/whenever there is push/check-in happened =
in
       GitHub, there might be chances sometimes check-in may not immediately
       reflect in GitHub but after few seconds will updated. So by waiting =
some
       sleep time will fix this kind of issues.
SCM
      Checkout retry count
There might be scenar=
ios
       Jenkins may failed to run job because of network glitches while clon=
ing
       the code from GitHub.
Instead of failing job if its fai=
led to
      clone repository for first time, we mention the number of times that
      jenkins has to try to clone the repository in jenkins. Since we are
      re-trying multiple times to clone repository there will be chances
      getting completed are high.
Create Jenkins Job to
      download source code
New Item
à
SCM checkout
à
Clone repo from master
<=
/span>
à
the error message we=
 are
       getting jenkins not sure where git installed.
New Item
à
SCM checkout
à
Clone repo from master
à
Job will passed
SCM Checkout
<=
span
       style=3D'font-family:Wingdings;font-size:11.0pt'>à
Update branch abc
à
Job Failed
Update the SCM Checko=
ut
       retry count in Jenkins, so Jenkins makes the job to run this many ti=
mes
       to clone repo.
Restr=
ict
      project Naming
As of now we creating=
 jobs
       with any name, correct/not? - Correct
If you want to create=
 job
       name with specific name, give pattern name as test*
Now try to create job=
 with
       name Check-test, it will not allow us to create.
Try to create a job w=
ith
       name Test, it will allow us to create job.
As of we are going wi=
th
       Default
Global
      Properties
Suppose you want to d=
eclare
       the environment variables for all the jobs, we can declare those
       variables here.
Global Properties
à
Environment Variable=
s
à
Key1
è
Value1
Now the environment
       variable Key1 & its value available for all the jobs as $Key
Tool locations
à
We can mention tools=
 that
       should be used for all the projects.
Jenki=
ns
      Location
Jenkins URL
à
Mention correct IP a=
ddress
       of machine where Jenkins installed.
Email
à
Email that is used t=
o send
       notification once builds are passed/failed.
Shell Executable
à
Mentions location of =
the
       shell that Jenkins to be used.
Jenkins by default us=
e bash
       shell
If you want to use windows shell you can C:\cmd.ex=
e
Manage Plugins
Why =
do we
       need plugins?
Plugins will provide features that
helps to integrate the Jenkins with other tools like,
Git
Maven
Sonarqube
Docker
Ansible
Kubernetes …etc.
Why d=
o we
      need to integrate Jenkins with other tools?
In order to meet the pipeline setup requirements.
The Plugins are in for=
mat
      like
.hpi
Where=
 can
      we find the plugins?
Manage jenkins -->
       Manage Plugins
=
Insta=
lled
      plugins:
This section will dis=
play
       list of installed plugins.
These are the basic p=
lugins
       that are installed during jenkins installation.
On Jenkins
server we can find plugins that=
 are
       installed in
<Jenkins_homedir>/plugins
folder
Available plugins:
From this section we can choose the plugin that are
       needed to integrate with Jenkins.
Suppose If I want integrate jenkins with Sonarqube=
 I
       have to install the
sonar-scanner
plugin.
Manage jenkins --> Manage plugins --> Avail=
able
        --> sonar-scanner
Now jenkins will install the sonar-scanner plugin
        along with dependencies.
Next open jenkins job it will show the options to
        configure sonarqube related commands.
Without sonar-scanner plugin you can't able to see
        this options.
Updates:
Click on
Updates.
Search the plugin you want to upgrad=
e in
       the search box
Here, we can see the
       latest version and the currently installed version of the plugin.
Click the checkbox to the required
       plugin.
After that, Click the
Download now and install after restart
button.
How to uninstall the plugin in Jenkins?
Click on
Installed plugins
.
Search the plugin that you want to
       uninstall in the search box
Click on the
Uninstall
icon.
=
Install plugin=
 by
      uploading hpi
How to integrate Jenki=
ns
      with sonarqube
Pre-=
requisites
Install sonar-scanner
        plugin
Repo:
https://github.com/c=
haitanyaredd/onlinebookstore.git
Git
Maven
Sonar-scanner
=
Jenkins
Sonarqube(In separat=
e EC2)
Integration of Jenkins=
 with
      sonarqube
First step Generate User Token on sonarqube server
Log=
 in to
        SonarQube Server and go-to the “
My Account
”=
 section
        on your profile. And move to the “
Security
”=
 tab.
        Then, Generate a “
User Access Token
=
.=
Login > Profile > My Account > Security > Generate
      Token
Add SonarQube Authentication Token Into Jenkins
Head-over to Jenkins server =
and
 go-to
Jenkin=
s >
 Credentials > System > Global Credentials > Add Credentials
Kind
=
: Secret test
Secret
: SonarQube Authentication Token
Description=
: Provide a descriptive name
Click
OK
to add new credentials.
Add SonarQube Server on Jenkins
Now, We need to add SonarQube
 server settings into Jenkins.
Manage Jenk=
ins
 > Configure System > SonarQube servers
Add Sonar-Scanner For Jenkins in Global tools configuration
Go to Jenkins > Manage Je=
nkins
 > Global Tool Configuration > SonarQube Scanner [Scroll Down] > A=
dd
 SonarQube-Scanner
Create free-style job & execute sonar-scanner analysis
(work-out
      practically)
Jenkin=
s-Day-4
07
December 2023
18:=
10
What is Tomcat server?
Tomcat is web application server.
What is web application?
Sites like
www.amazon.com
/
www.facebook=
.com
/
www.netflix.com
are conside=
red
      as web applications.
The web applications artifacts like .war files we can deploy on
     tomcat server & can access those deployed programs via browsers
How to
     install & configure Tomcat?
To install tomcat we ne=
ed
pre-re=
quisites
like
Insta=
ll
      java-11
List java-11
       related packages are available
yum
list | grep -i java-11*
Install the java-11
yum
install java-11* -y
Check the java version
java
-version
Downlo=
ad the
     tomcat binary from internet & extract it, later copy it to the /opt
     folder
wget
https://archive.apache.org/dist/tomcat/tomcat-10/v=
10.1.13/bin/apache-tomcat-10.1.13.tar.gz
tar
-xzvf apache-tomcat-10.1.13.tar.gz
mv
apache-tomcat-10.1.13 tomcat
mv
tomcat /opt/
Start =
tomcat
./opt/tomcat/bin/startup.sh
Check =
tomcat
     is running or not
ps
-ef | grep -i tomcat
Now tomcat is accessibl=
e on
     browser with URL
http=
://<ip-address>:8080
Update content.xml file=
 to
     in-order to have manger-app/server-status check access,
vi
/opt/tomcat/webapps/manager/META-INF
To log=
in
     tomcat setup via GUI credentials
vi
/opt/tomcat/conf/tomat-users.xml
To dep=
loy
     applications into tomcat we have to user role "manager-script&quo=
t;
Let's
     manually deploy sample web application & check manually we are abl=
e to
     access or not.
cd
/opt/tomcat/webapps
wget
https://tomcat.apache.org/tomcat-7.0-doc/appdev/sample/sample.war
Now
we are able to sample application through tomcat.
In this case for your
     understanding purpose only I download the .war file directly from
     internet, but in real-time we have to create it out of source code &am=
p;
     later we deploy to tomcat server.
Deploy=
 web
     applications on tomcat via jenkins pipeline.
Now we will discuss how=
 to
     download latest code from GitHub, build that code & deploy tomcat
     server with help of jenkins we will see.
Pre-re=
quisites:
EC2-SERVER-1(t2.medium=
)
Git
Maven
Java
Jenkins
Repo: online-bookstor=
e
EC2-server-2(t2.micro)<=
/span>
Tomcat
Deploy to container plu=
gin
Free-s=
tyle
     job configuration
src:
https://github.com/cha=
itanyaredd/onlinebookstore.git
Build: mvn clean insta=
ll
Post build steps:
Provide location of w=
ar
       file: **/.war {recursively look under the workspace folder for war f=
ile}
Provide context as you
       want, since we are configuring deployment for online-bookstore, I am
       giving as online-bookstore
Choose tomcat contain=
er as
       tomcat-9.x
Enter tomcat url
Enter tomcat credent=
ials -
        (The credentials must have the manager-script role, then we can dep=
loy
        application to tomcat from jenkins)
Save --> Apply
Now execute the job
Now we can able the acc=
ess
     the online-bookstore application
http://<tomcat=
-server>:8080/online-bookstore
Discard old builds
Choose custom workspace
Archive the jar/war files
Publish junit reports
Jenkin=
s-Day-5
08
December 2023
18:=
51
How to
     integrate Jfrog with Jenkins & upload artifacts
Pre-re=
quisites
EC2-SERVER-1
Git
Maven
Jenkins
Repo: online-bookstor=
e
EC2-SERVER-2
JFROG
EC2-SERVER-3
Tomcat
Artifactory plugin
Create a new Freestyle
     project in Jenkins.
Configure your source c=
ode
     repository if your job involves source code.
Configure Build Steps:<=
/span>
mvn clean install
To upload
      artifacts to Artifactory, you can use the "Deploy artifacts to
      Artifactory" build step. Provide the necessary details like the
      target repository, path, and artifacts to deploy.
Example for uploading artifacts:
sh
'echo "Build completed"'
rtUpload (
serverId:
<=
span
      style=3D'font-family:Calibri;font-size:11.0pt;color:#00A67D'>'Artifac=
toryServer'
,
spec:
'''{
"files&qu=
ot;:
      [
{
"=
pattern":
      "target/*.jar",
"=
target":
      "libs-release-local/"
}
]
}'''
)
How to
     integrate Jfrog with Jenkins & download artifacts
To download artifacts from Artifactory, you can use the
"Download artifacts from Artifactory" build step. Provide the
necessary details like the source repository, path, and artifacts to
download.
Example for downloading artifacts:
rtDownload (
serverId:
'ArtifactoryServer',
spec: '''{
"files": [
{
"pattern"=
;:
"libs-release-local/*.jar",
"target":
"downloaded-artifacts/"
}
]
}'''
)
Jenkin=
s-Day-6
08
December 2023
19:=
12
Jenkin=
s file
Normal=
ly in
     Jenkins how do we create & configure the jobs?
GUI
way.
What i=
s the
     problem when your jenkins server crashed?
You have to recreate j=
enkins
      server and
recreate the jobs and it's configurations
.
This will be tedious ta=
sk
     because you will have many number of jobs and lot of configurations so
     there is no chance of remembering to all those job details and
     configurations.
Also when multiple devo=
ps
     engineers are working on same jerkins instance it is very difficult wh=
at
     another person made the configuration changes on the jobs.
To avoid this problem w=
e can
     use jenkinsfile script in order to maintain the configurations of the =
jobs
     & and we will maintain this script file in GitHub.
Since we are maintainin=
g the
     jenkinsfile
in the GitHub, i=
t is
     easy to track the pipeline changes and get review those changes.
We can write the script=
 for
     the Jenkins file two ways
one is
scri=
pted
      pipeline
another one is
=
decla=
rative
      pipeline
Declarative pipeline is mu=
ch
more easy compared to the scripted pipeline this is developed by the Jenkins
team to make the people more convenient to write the Jenkins file.
But if you want to write
scripted by plane you need to have knowledge on the groovy script.
Scripted pipeline syntax l=
ooks
like
node(
//groovy script
)
Declarative pipeline syntax
looks like
Now let's go to the offici=
al
site of the chin games and we will take a look how the scripted pipeline and
declarative pipelines syntax.
Here you can see scripted =
by
plane there is a stage test stage and placed similarly in the declarative
pipeline also we can see build stage and depli station so here the stage
nothing but job in the Jenkins.
Now let's copy this declar=
ative
pipeline code and do some modifications in order to run the pipeline.
As of now in each stage I =
am
just printing the statement what is stages doing but in our real time we ha=
ve
to enter the commands that we need to run.
Pic-3
Usecase1: Run Jenkins file=
 from
the Jenkins job only instead from GithHub.
To use the declarative pipeline we have to insta=
ll
pipeline plugin.
Pic-4
Usecas=
e2:
     how to run multi step shell commands in jenkinsfile
pipeline
{
agent
any
stages
{
stage('Test-Multi-shell-commands'){
steps
{
sh
'echo "Executing first command"'
sh
'''
echo
"Executing second command"
pwd
ls
-ltr
'''
}
}
}
}
Usecas=
e3:
     use retry option whenever them are any command is failing frequently.<=
/span>
pipeline
{
agent
any
stages
{
stage('Timeout'){
steps
{
retry(3){
sh
'echo "retriggering the command"'
}
}
}
}
}
Usecas=
e4:
     Fail the job if it is taking more than 60 seconds using time out optio=
n.
pipeline
{
agent
any
stages
{
stage('Timeout'){
steps
{
retry(3){
sh
'echo "retriggering the command"'
}
timeout(time:
30, unit: 'SECONDS') {
sh
'sleep 60'
}
}
}
}
}
Usecas=
e5:
     how to set environment variables in the pipeline
pipeline
{
agent
any
environment
{
NAME
=3D "Chaitanya"
COUNTRY
=3D "India"
}
stages
{
stage('Env
variables') {
steps
{
sh
'echo $NAME $COUNTRY '
}
}
}
}
Usecas=
e6:
     post steps after the job completed
pipeline
{
agent
any
environment
{
NAME
=3D "Chaitanya"
COUNTRY
=3D "India"
}
stages
{
stage('Env
variables') {
steps
{
sh
'echoxea $NAME $COUNTRY '
}
}
}
post
{
success
{
echo
"This will executed when job is success"
}
failure
{
echo
"This will executed when job is failed"
}
unstable
{
echo
"This will executed when job is unstable"
}
always
{
echo
"This will executed irrespective of job status"
}
}
}
Usecase7: How to execute maven command
Jenkin=
s-Day-7
05
October 2023
12:=
39
Requirement:
&nb=
sp;
Pre-requisites
EC2 instance
       with t2.large
Git
Maven
Sonarqube
Jenkins
Sonarqube
        plugin
Artifactory plugin
Artifactory
--> t2.large
Tomcat
--> t2.large
Plugins
Artifactory=
Sonarqube scanner
Pipeline utility
        steps(Find files for binary deploy to tomcat deployments)
Deploy to container =
Clone repo using jenkinsfile
pipeline
 {
agent any
stages{
stage('clone') {
steps {
checkout scm
}
}
}
}
Build the code
pipeline
 {
agent any
stages{
stage('clone') {
steps {
checkout scm
}
}
stage('Build') {
steps {
sh 'mvn clean install'
}
}
}
}
Build will failed due to maven command not
      found & define the
mave=
n
pipeline
 {
agent any
tools {
maven 'maven-3.6.3'
}
stages{
stage('clone') {
steps {
checkout scm
}
}
stage('Build') {
steps {
sh 'mvn clean install'
}
}
}
}
Do sonar scanning, it will fail due sonar
      scanner plugin not present & sonar. Login not defined
pipeline
 {
agent any
tools {
maven 'maven-3.6.3'
}
stages{
stage('clone') {
steps {
checkout scm
}
}
stage('Build') {
steps {
sh 'mvn clean install'
}
}
stage('sonarqube-scanning'){
steps {
withSonarQubeEnv('My Sona=
rQube
 Server') {
sh 'mvn sonar:sonar'<=
/p>
}
}
}
}
}
Do sonar scanning with the
      parameters
pipeline
 {
agent any
tools {
maven 'maven-3.6.3'
}
stages{
stage('clone') {
steps {
checkout scm
}
}
stage('Build') {
steps {
sh 'mvn clean install'
}
}
stage('sonarqube-scanning'){
steps {
withSonarQubeEnv('My Sona=
rQube
 Server') {
sh 'mvn sonar:sonar \=
-Dsonar.projectKey=3Donline-book-store \
-Dsonar.projectName=3D"online-book-store" \
-Dsonar.login=3Dsqa_f78d0d4e2a2be94550489789968eff5b801e53f9'
}
}
}
}
}
Add quality gate to the jenkins=
file
pipeline
 {
agent any
tools {
maven 'maven-3.6.3'
}
stages{
stage('clone') {
steps {
checkout scm
}
}
stage('Build') {
steps {
sh 'mvn clean install'
}
}
stage('sonarqube-scanning'){
steps {
withSonarQubeEnv('My Sona=
rQube
 Server') {
sh 'mvn sonar:sonar \=
-Dsonar.projectKey=3Donline-book-store \
-Dsonar.projectName=3D"online-book-store" \
-Dsonar.token=3Dsqu_c7fbb3bf3647607967ac2ed5a162ed0c5603bc67'
}
}
}
stage("Quality Gate") {=
steps {
retry(3) {
sh 'sleep 30s'
waitForQualityGat=
e abortPipeline:
 true
}
}
}
}
}
Fail the pipeline by enabling
      quality gate in sonarqube
pipeline
 {
agent any
tools {
maven 'maven-3.6.3'
}
stages{
stage('clone') {
steps {
checkout scm
}
}
stage('Build') {
steps {
sh 'mvn clean install'
}
post {
always {
archiveArtifa=
cts artifacts:
 '**/*.war', onlyIfSuccessful: true
}
}
}
stage('sonarqube-scanning'){
steps {
withSonarQubeEnv('My Sona=
rQube
 Server') {
sh 'mvn sonar:sonar \=
-Dsonar.projectKey=3Donline-book-store \
-Dsonar.projectName=3D"online-book-store" \
-Dsonar.token=3Dsqu_c7fbb3bf3647607967ac2ed5a162ed0c5603bc67'
}
}
}
stage("Quality Gate") {=
steps {
retry(3) {
sh 'sleep 30s'
waitForQualityGat=
e abortPipeline:
 true
}
}
}
stage('Upload to Artifactory') {<=
/p>
steps {
script {<=
/p>
/=
/ Define a new
 Artifactory server instance
d=
ef server =3D
 Artifactory.server 'jfrog-instance'
//
 Replace 'ServerID' with your Artifactory server ID from Jenkins configurat=
ion.
<=
/p>
/=
/ Define the artifact
d=
ef uploadSpec =3D
 """{
=
"files": [
=
{
=
"pattern": "**/*.war",
=
"target":
 "online-bookstore/${BUILD_ID}/onlinebookstore-1.0.war"
=
}
=
]
}=
"""
/=
/ Upload the artifact
s=
erver.upload(uploadSpec)
}
}
}
}
}
Download the artifact from jfro=
g to
      server
Install JFRO=
G
Create repo in jfrog =
maven
       based "online-bookstore" repo
Install artifactory p=
lugin
Integrate Jenkins &am=
p;
       Artifactory
pipeline
 {
agent any
tools {
maven 'maven-3.6.3'
}
stages{
stage('clone') {
steps {
checkout scm
}
}
stage('Build') {
steps {
sh 'mvn clean install'
}
post {
always {
archiveArtifa=
cts artifacts:
 '**/*.war', onlyIfSuccessful: true
}
}
}
stage('sonarqube-scanning'){
steps {
withSonarQubeEnv('My Sona=
rQube
 Server') {
sh 'mvn sonar:sonar \=
-Dsonar.projectKey=3Donline-book-store \
-Dsonar.projectName=3D"online-book-store" \
-Dsonar.token=3Dsqu_c7fbb3bf3647607967ac2ed5a162ed0c5603bc67'
}
}
}
stage("Quality Gate") {=
steps {
retry(3) {
sh 'sleep 30s'
waitForQualityGat=
e abortPipeline:
 true
}
}
}
stage('Upload to Artifactory') {<=
/p>
steps {
script {<=
/p>
/=
/ Define a new
 Artifactory server instance
d=
ef server =3D
 Artifactory.server 'jfrog-instance'
//
 Replace 'ServerID' with your Artifactory server ID from Jenkins configurat=
ion.
<=
/p>
/=
/ Define the artifact
d=
ef uploadSpec =3D
 """{
=
"files": [
=
{
=
"pattern": "**/*.war",
=
"target":
 "online-bookstore/${BUILD_ID}/onlinebookstore-1.0.war"
=
}
=
]
}=
"""
/=
/ Upload the artifact
s=
erver.upload(uploadSpec)
}
}
}
stage('Download from Arti=
factory') {
steps {
script {<=
/p>
sh 'mkdir -p
 ${WORKSPACE}/ready_deploy_binary/'
/=
/ Define the Artifactory
 server instance
d=
ef server =3D
 Artifactory.server 'jfrog-instance'
//
 Replace 'ServerID' with your Artifactory server ID from Jenkins configurat=
ion.
/=
/ Define download spec
d=
ef downloadSpec =3D
 """{
=
"files": [
=
{
=
"pattern":
 "online-bookstore/${BUILD_ID}/onlinebookstore-1.0.war",
=
"target": "${WORKSPACE}/ready_deploy_binary/"
=
}
=
]
}=
"""
/=
/ Download the artifact
s=
erver.download
 downloadSpec
}
}
}
}
}
Deploy Artifact to tomcat serve=
r
Install tomc=
at
Create users with
       Manage-gui & Manage-script role
Install deploy to con=
tainer
       plugin
Define tomcat username
       & password in jenkins
Install credentials b=
inding
       plugin
Install BUILD_TIMESTA=
MP
Correct the TIMESTAMP=
 as
       "yyyy-MM-dd-HH-mm-ss-z"
pipeline
 {
agent
 any
tools
 {
maven
 'maven'
}
stages
 {
stage('clone-repo'){
steps
 {
checkout
 scm
}
}
stage('Build')
 {
steps
 {
sh
 'mvn clean install'
}
}
stage('sonarqube-scanging'){
steps
 {
withSonarQubeEnv('my-sonarqube-server')
 {
sh
 'mvn sonar:sonar'
}
}
}
stage('quality-gate-check'){
steps
 {
sh
 'sleep 30s'
waitForQualityGate
 abortPipeline: true
}
}
stage('artifactory-upload'){
steps{
script
 {
//
 Define a new Artifactory server instance
def
 server =3D Artifactory.server 'jfrog-instance'
// Replace 'ServerID' with your Artifactory server ID from Jenkins
 configuration.
//
 Define the artifact
def
 uploadSpec =3D """{
"files":
 [
{
"pattern":
 "**/*.war",
"target":
 "online-bookstore/${BUILD_TIMESTAMP}/onlinebookstore-1.0.war"
}
]
}"""
//
 Upload the artifact
server.upload(uploadSpec)
}
}
}
stage('download
 from artifactory'){
steps{
script{
sh
 'mkdir -p ${WORKSPACE}\readytodeploy'
def
 server =3D Artifactory.server 'jfrog-instance'
def
 downloadSpec =3D """{
=
"files": [
=
{
=
"pattern":
 "online-bookstore/${BUILD_TIMESTAMP}/onlinebookstore-1.0.war",
=
"target": "${WORKSPACE}/ready_deploy_binary/"
=
}
=
]
}=
"""
/=
/ Download the artifact
s=
erver.download
 downloadSpec
}
}
}
stage('Deploy
 to Tomcat') {
steps
 {
//
 Use Jenkins credentials binding
withCredentials([usernamePassword(credentialsId:
 'TomcatCredentials', usernameVariable: 'TOMCAT_USER', passwordVariable:
 'TOMCAT_PASS')]) {
script
 {
def
 tomcatUrl =3D '
=
http://18.234.161.208:8080/manager/text/deploy
'
def
 warFile =3D
 '${WORKSPACE}/ready_deploy_binary/${BUILD_TIMESTAMP}/onlinebookstore-1.0.w=
ar'
 // Adjust the path to your WAR file.
echo
 "Executing: curl -T ${warFile} -u $TOMCAT_USER:$TOMCAT_PASS
 '${tomcatUrl}?path=3D/your-context-path&update=3Dtrue'"
sh
 """
curl
 -T ${warFile} -u $TOMCAT_USER:$TOMCAT_PASS
 "${tomcatUrl}?path=3D/online-bookstore&update=3Dtrue"
"""
}
}
}
}
}
}           &nb=
sp;
Make sure jfrog & tomcat de=
ploy
      runs only on master branch
when
 {
//
 Only run this stage when the BRANCH_NAME is 'master'
expression
 {
env.BRANCH_NAME
 =3D=3D 'master'
}
}
Ansibl=
e-Day-1
11
December 2023
17:=
06
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Introd=
uction
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Before we discuss about
     Ansible first will discuss about configuration management tool.
=
What is
     configuration Management?
Normally how we will i=
nstall
      some software in any machine,
We just login to server manually=
Install the required software (t=
omcat)
Do the changes in
       configuration of software files to make our application run smoothly=
.
Now assume when you have
     situations to install same software
on large number of servers,
Consume lot of time to
      perform installation/configuration
Chances for human erro=
rs
Lot of human efforts
      required
To overcome this issues
     configuration management tool came into picture.
CM
tool taken responsibility for making the target systems & software's in
desired and consistent state.
In market we have diffe=
rent
     types of CM tool's
Ansible
Chef
Puppet
Salt
Ansibl=
e
not only acts as
configuration management tool
but it also support
orchestration tool.
=
Orches=
tration
     tool nothing provisioning/creating resources like ec2 on public clouds
     like ec2,alb..etc. similar to terraform.
But best for choosing A=
nsible
     for CM & terraform as orchestration tool since some of advanced
     feature in terraform.
Out of these CM tools A=
nsible
     is the widely used CM tool.
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Ansible
     architecture
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Create & Explain di=
agram
     ansible_day_1.png
=
Ansibl=
e-controller:
It's a server where An=
sible
      is installed .
From this server we can
     control the install/update/delete configurations for the software on
     particular machines.
Mostly the controller s=
ervers
     is on RHEL OS.
Node: =
It's a server
<=
span
      style=3D'font-weight:bold;font-family:Calibri;font-size:11.0pt'>where=
 we
      have to install/Update/Configure software
through the Ansible controller.
Node machine can run on=
 any
     OS Linux/Ubuntu/Windows
The connectivity establ=
ished
     from Ansible controller to target machines using SSH key based
     authentication.
On target servers we do=
n't
     required to install any agent software to establish connectivity to
     controller.
hosts =
Contains the list of t=
arget
      machines IP/hostnames.
Playbo=
ok
The script files that =
we
      have written to automate the tasks.
What is
     task?
Downloading
file from internet/Unzipping the file ….etc are consider as tasks.
The playbooks will be w=
ritten
     in yml format.
YAML nothing but Yain't
     mark-up language.
It's a declarative lang=
uage.
     Easy to understandable & writable.
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D
Why An=
sible
     is popular than chef?
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D
Ansible works on push b=
ased
     mechanism but chef works on pull based mechanism.
Suppose you want to ins=
tall
     tomcat software on node machines, the controller machine pushes the
     commands/configurations that needs to be executed node machines.
Chef client on node mac=
hines
     pulls the configuration/commands that needs to be executed from chef
     server. So Chef is working on pull based mechanism.
Ansible is a agentless
     configuration management tool but chef is an agent based configuration
     management tool.
On Node machines chef-c=
lient
     software need to be installed & this client will connect to the
     chef-server and pulls the configurations on regular intervals.
=
For Ansible we don't ne=
ed to
     install any software on machines.
Ansible is supported by
     Red-hat systems, so this is add-on all Unix flavours.
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D
Ansible
     setup
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D
Create one Ansible cont=
roller
     & 3 target machines (RHEL, Amazon Linux, Ubuntu)
Prepare Ansible control=
ler
     server/EC2
Create EC2
      instance
Create ansible user
Add ansible user to su=
doers
      file
Generate SSH keys for
      ansible user
Enable password based
      authentication
Check python presence<=
/span>
Install ansible
=
Prepare target node
Create EC2
      instance
Create ansible user
Add ansible user to su=
doers
      file
Enable password based
      authentication
Check python presence<=
/span>
Copy the key of ansible=
 user
     from controller to target machine ansible user
ssh-copy-id ansible@<target-ec2-ip>
=
Adding target machine d=
etails
     into inventory file
Test the connectivity f=
rom
     controller to target machines
ansible -m ping all
Provide some wrong IP a=
ddress
     & check connectivity
Ansibl=
e-Day-2
11
December 2023
19:=
13
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Ansible
     components
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Before jump into ansible
     further we have to get familiar with few of terminologies in ansible
/etc/a=
nsible/ansible.cfg
Is the default configu=
ration
      file of ansible, which is useful to manage ansible playbooks or ansib=
le
      commands.
=
I will discuss more det=
ails
     with example in sometime.
=
/etc/a=
nsible/hosts
Is the default invento=
ry
      file.
It contains list of tar=
get
     machine IP addresses/hostnames.
tasks =
Activities that we are=
 going
      to managed on target servers.
Installing git activi=
ty on
       target server will be considered as one activity.
yum
install git -y
Starting the
httpd<=
/span>
service activity on ta=
rget
     server will be considered as one activity.
systemctl
start httpd
playbo=
oks
Playbooks are collecti=
on of
      tasks
module=
s
Modules are predefined
      commands/units which are used inside the playbooks or commands in ord=
er
      to execute on target machines.
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Ansible Ad-hoc commands
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
When you have a need of=
 run
     repeated task on setup of servers then we can use ansible ad-hoc comma=
nds.
Assume in your company =
there
     are 1000 servers are there & out these servers how many servers are
     running & how many servers are not running, how can you find it us=
ing
     ansible?
ansible
-m ping all
syntax:
ansible -m <module_name> -a
"argument" <group_name/all>
Command
     module
:-
Used execute any shell command ta=
rget
     machine, then we use shell command
Find out uptime of the list of ser=
vers.
ansible -m command -a "uptime=
"
all
Find out the home directory of ans=
ible user
in target machines
ansible -m command -a "pwd&qu=
ot; all
stat:<=
/span>
Displays the statics o=
f the
     file,
what =
is
      statistics of a file?
Who is the owner of f=
ile?
What permissions are =
there
       on file?
Is it directory or fi=
le?
ansible
-m stat -a "/etc/hostname" all
group<=
/span>
: Used to create/delete
     groups on target machines
{C=
ache
     issue}
Create a Unix user gro=
up
      with ansible ad hoc command
Create a user name group
     named
dbadmin
using the ansible group module.
ansible
-i ~/hosts -m group -a "name=3Ddbadmin state=3Dpresent" all
Delete a user name group named
dbadmi=
n
using the ansible group
     module.
ansible -i ~/hosts -m group -a
"name=3Ddbadmin state=3Dabsent" all
COPY
: Used to copy the file=
s to
     target machine from controller machine
ansible
-i ~/hosts -m copy -a "src=3D/etc/hosts dest=3D/tmp/hosts mode=3D600&q=
uot;
file: =
To create a file/direct=
ory on
     target nodes
Create a new directory=
 with
      755 permission
ansible
-m file -a "path=3D/opt/oracle state=3Ddirectory mode=3D0755" all=
Create a new file with =
755
     permission
ansible
-m file -a "path=3D/opt/oracle state=3Dfile mode=3D0755" all
yum: <=
/span>
Install a package or so=
ftware
     in Linux using yum module of ansible
ansible -m yum -a &q=
uot;name=3Dhttpd
state=3Dinstalled" all
Remove sudo access on t=
arget
     & repeat yum module, if we don't have sudo access on remote
     installation will be failed.
servic=
e:
start/stop httpd servic=
e on
     target machine
Start httpd service &am=
p;
     enable it to auto restart on server reboot
ansible
-m service -a "name=3Dhttpd state=3Dstarted enabled=3Dyes" all
To Stop
ansible
-m service -a "name=3Dhttpd state=3Dstop enabled=3Dyes" all
get_ur=
l:
Download a file from UR=
L in
     ansible
ansible
-m get_url -a
"url=3Dhttps://nodejs.org/dist/v14.17.4/node-v14.17.4-linux-x64.tar.xz
dest=3D/tmp mode=3D0755" all
setup:=
Displays facts about the
     target machines.
What do you meant by f=
acts
      of target machines?
Ip-address
Hostname
OS family
Architecture
Network configuration=
s
RAM
File system details
ansible
-m setup all
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Inventory file
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
The inventory file have=
 a set
     of nodes on which we are going to install/update/delete/configure
     software.
The default inventory f=
ile is
/etc/ansible/hosts
We can't change every t=
ime
     the default inventory file we can change it using -i option
-i
hosts
Use inventory file othe=
r than
     default inventory file
ansible -i ~/hosts -=
m command -a
"uptime" all
We can change the inven=
tory
     file location to different file permanently by modifying ansible.cfg
inventory=3D/root/host=
s
library =3D=3D> Cont=
ains
     modules that are present ansible
remote_tmp =3D=3D> W=
hen we
     execute ansible commands it requires some temporary space required
on remote side.
local_tmp =3D=3D> Wh=
en we
     execute ansible commands it requires some temporary space required
on local side.
forks =3D=3D> The nu=
mber of
     parallel executions on target machine
suppose if you have 100
      machines & fork count is 5 only first 5 servers completed & n=
ext
      go for another 5 like that till 100
poll_intervel =3D=3D>=
;
module =3D command {def=
ault
     module that can picked automatically when we haven't provided in adhoc
     commands}
ansible
all -a "uptime"
Change the module from
     command to yum
ansible
all -a "name: git state: present"
Change module to yum &a=
mp;
     execute
ansible
all -a "name: git state: present"
Explain Idempotency
=
Explain change/without &am=
p;
Ansibl=
e-Day-3
13
December 2023
12:=
05
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D
Ansible modules
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D
Modules are predefined
     commands/units which are used inside the playbooks or commands in orde=
r to
     execute specific tasks on target machines.
Ansible have large exte=
nt
     number of modules, we can view it on ansible community side.
Explain user module &am=
p;
     required parameters
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D
Ansible playbook syntax
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D
Ansible playbook is a t=
ext
     file written in YAML(Ain't markup language) & stored with format .=
yml
The sample format of th=
at
     ansible playbook appears as
---
-
hosts: all
become: yes
gather_facts: yes
tasks:
- task1
- task2
- task3
Where
--- Indicates the start=
ing of
     the playbook
- hosts: Points the lis=
t of
     hostnames that we are targeting to configure.
gather_facts: Capture t=
he
     facts about the target machines
become: The ansible user
     becomes the root.
tasks: List of the acti=
vities
     that we are going to do.
task1: activity that we=
 are
     going to do
=
Ex:
=
- name:
"Installing git"
=
yum:
=
name: git
=
state: present
Create=
 a
     playbook for userid creation
---
-
hosts: all
become: yes
gather_facts: yes
tasks:
user:
name: dhoni
state: present
ansible-playbook -i ~/h=
osts
     -v user_creation.yml
The
output appears in the following format
PLAY RECAP
***************************************************************************=
***************************************************************************=
**************************************
client-0x0001
: ok=3D5
changed=3D0
unreachable=3D0
failed=
=3D0
skipped=3D0
rescued=3D0
ignored=3D=
0
changed =3D=3D> The state of t=
he target
     machine modified after executing particular task.
ok =3D=3D> means there was no =
change on
     target machine state after executing particular task.
unreachable =3D=3D> Not able t=
o connect
     target machine, try with wrong ip address
failed =3D=3D> Specific task f=
ailed due
     to some errors , try with error wrong package name
skipped =3D=3D> Particular task skipped to run on specific =
host
     machine, run a task only on Ubuntu {Discuss during conditional stateme=
nts}
tasks:
- name: "Install git =
on
rhel"
yum:
name: git
state: present
when: ansible_os_family =3D=3D rhel8
- name: "Install tree=
 on
ubuntu"
apt:
name: tree
state: present
when: ansible_os_family =3D=3D ubuntu
rescued: Need to work on t=
his.
{Discuss during conditional statements}
Explain every line ansible-day-3.png image
The playbooks uses the
     indentation with spaces in order to indicate structure of the data.
---
-
hosts: all
become: yes
tasks:
-
user:
name:
john
state:
present
Since
we didn't followed indentation in right format we received syntax errors.
gather_facts =3D=3D>=
Used to fetch target ma=
chine
     meta data details/facts
Example:
"ansible_nodename":
"ip-172-31-21-77.ec2.internal",
"ansible_os_family":
"RedHat",
"ansible_pkg_mgr":
"yum"
By default gather_facts=
 are
     enabled
When we don't have any =
need
     of facts we can disable it by setting gather_facts to no
---
-
hosts: all
become: yes
gather_facts: no
tasks:
-
user:
name:
john
state:
present           &n=
bsp;
become=
This used to get privi=
lege
      escalation option & converts ansible user to get sudo privilege's=
,
similarly that we used
     "-b" option in ad-hoc commands during group creation.
=
UC:- C=
reate
     a user with become no option.
---
- hosts: all
gather_fac=
ts: no
become: no=
tasks:
- name=
: "create
user"
us=
er:
name: john
state: present
ansible-playbook -i ~/h=
osts
     -v user_creation.yml
The execution will get =
failed
     due to the permissions issue & we can solve it by setting become to
     yes.
By default become is se=
t to
     no, if we don't use become option in our playbooks.
--chec=
k
:
When ansible-playbook =
is
      executed with --check it will not make any changes on remote systems.=
It will display report what changes =
they
would have made rather than making them.
UC:- C=
reate
     a playbook for kohli user creation & before execute the playbook r=
un
     it on check mode
On ta=
rget
machine we don't see the kohli user after mode, since mode id dry run,
It
just report user creation changes is going to happen
---
- hosts: all
become: ye=
s
gather_fac=
ts: no
tasks:
- name=
: "create a
user"
us=
er:
name: kohli
state: present
ansible-playbook -i ~/h=
osts
     -v user_creation.yml --check
Even
we have executed our playbook, it hasn't created kohli user, It's just repo=
rted
the changes what are all going happen.
Remove the --check opti=
on
     & execute playbook, now kohli user added on target system.
<=
/li>
ansible-playbook
-i ~/hosts -v user_creation.yml
UC1:- =
Create
     a playbook for installing "git" package on ubuntu & rhel
     machine.
---
-
hosts: all
gather_facts: no
become: yes
tasks:
-
name: "Install git"
yum:
name:
git
state:
present
ansible-playbook -i ~/h=
osts
     -v git_install.yml
The execution will be f=
ailed
     due to By default
"yum" will acts package =
repo for
RHEL machines &
=
"apt" will acts package repo for Ubuntu machines.
To overcome this issue we use
     "package" module to support installation of packages on any
     Linux flavours when package name same for all flavours.
---
- hosts: all
gather_facts: no
become: yes
tasks:
- name "Installing gi=
t"
package:
name: git
state: present
ansible-playbook -i ~/hosts -v
git_install.yml
UC2:-
     Playbook for Install apache(httpd) webserver, start it & later
     configure it
yum
install httpd
service
httpd start
echo
"Welcome to ansible" > /var/www/html/index.html
---
- hosts: all
become: yes
gather_facts: no
tasks:
- name: "Installi=
ng httpd"
yum:
name: httpd
state: present=
- name: "starting=
 httpd
service"
service:
name: httpd
state: started=
- name: "Configur=
e the httpd
service"
command: echo &quo=
t;Welcome to
ansible" > /var/www/html/index.html
ansible-playbook -i ~/hosts -v httpd_setup.yml
Grouping & subgrouping of servers
LAMP stack setup with installation commands & customize it
     with loop
Ansibl=
e-Day-4
13
December 2023
13:=
07
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D
LOOP in ansible
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D
loop keyword used to ex=
ecute
     the task multiple times.
Example:
- Creating multiple users with use=
r module
- Changing the ownership for multi=
ple files
Just few versions before
     instead of loop, with_items was used to support loop functionality &am=
p;
     now its depricated.
usecas=
e1:
     create testuser1,testuser2 & testuser3 using loop in the single ta=
sk
---
-
hosts: all
become: yes
gather_facts: no
tasks:
- name: "Creating user"<=
/p>
user:
name: "{{ item }}&quo=
t;
state: present
loop:
- testuser1
- testuser2
- testuser3
usecas=
e2:
     create 3 users(testuser1,testuser2 & testuser3) in three different
     groups(dev,test,prod) using loops
---
-
hosts: all
become: yes
gather_facts: no
tasks:
- name: "Creating user"<=
/p>
user:
name: {{ item.user }}
group: {{ item.group }}
state: present
loop:
- { name: 'testuser1', gro=
ups: 'dev' }
- { name: 'testuser2', gro=
ups: 'test' }
- { name: 'testuser3', gro=
ups: 'prod' }
usecas=
e3:
     Install multiple packages using loop {git,tree,wget}
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D
When condition
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D
"When" statem=
ent is
     a conditional statement that runs the particular task if the condition=
 is
     met.
usecas=
e1:-
     Create a playbook install apache webserver setup in Linux{httpd} &
     Ubuntu{apache2} machines
---
-
hosts: all
become: yes
gather_facts: no
tasks:
- name: "Installing httpd&quo=
t;
yum:
- name: httpd
state: present
- name: "Start httpd service&=
quot;
service:
name: httpd
state: started
- name: "Configure httpd"=
;
copy:
src: index.html
dest: /var/www/html/index.=
html
- name: "Installing apache2&q=
uot;
apt:
name: apache2
state: present
- name: "start apache2 servic=
e"
service:
name: apache2
state: started
- name: "configure apache2&qu=
ot;
copy:
src: index.html
dest: /var/www/html/index.=
html
Once I execute above playbook=
 all the
     tasks will run in sequential mode & execution failed on all ubuntu
     & rhel servers.
To overcome this is issue I am goi=
ng to use
when condition particular task, so when condition met then only respective =
task
will executed.
Capture OS family details,
ansible -m setup -a "filter=
=3D*os*"
all
gather_facts set to be true.
---
- hosts: all
become: yes
gather_facts: yes
tasks:
- name: "Installing h=
ttpd"
yum:
- name: httpd
state: present=
when: ansible_os_famil=
y =3D=3D
"RedHat"
- name: "Start httpd =
service"
service:
name: httpd
state: started
when: ansible_os_famil=
y =3D=3D
"RedHat"
- name: "Configure ht=
tpd"
copy:
src: index.html
dest: /var/www/htm=
l/index.html
when: ansible_os_famil=
y =3D=3D
"RedHat"
- name: "Installing a=
pache2"
apt:
name: apache2
state: present
when: ansible_os_famil=
y =3D=3D
"Ubuntu"
- name: "start apache2
service"
service:
name: apache2
state: started
when: ansible_os_famil=
y =3D=3D
"Ubuntu"
- name: "configure ap=
ache2"
copy:
src: index.html
dest: /var/www/htm=
l/index.html
when: ansible_os_famil=
y =3D=3D
"Ubuntu"
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D
Grouping =
of
Inventory
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D
Handlers
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D
It's a feature of ansib=
le,
     appears similar to the task.
Handlers will works onl=
y when
     it's called from another task using notify keyword.
When there is a need of
     running repetitive task after running particular task then we will use
     handlers.
Assume we have Apache
     installed & configured, after the configuration normally we requir=
ed
     to restart apache
In this case we will use handle=
rs.
Usecas=
e4:-
     Create playbook Apache setup using handlers
---
- hosts: all
become: yes
gather_facts: no
tasks:
- name: "Installing h=
ttpd"
yum:
name: httpd
state: present
- name: "Configuring =
httpd"
copy:
src: index.html
dest: /var/www/htm=
l/index.html
notify: Restart apache=
handlers:
- name: "Restart apac=
he"
service:
name: httpd
state: restarted
Ansibl=
e-Day-5
13
December 2023
14:=
25
How to
     declare variable in ansible playbooks
---
-
hosts: all
become: yes
var:
pkg_name: git
tasks:
- name: Install git
yum:
name: {{ pkg_name }}
state: present
Execute
the playbook the and show installation done successfully.
Overri=
de the
     git variable explicitly during ansible playbook execution
ansible-playbo=
ok -i hosts -v -e
"pkg_name=3Dtree" samp.yml
Define
     variables in /etc/hosts as host variables & group variables
=
[webserver]
10.1.2.100
pkg_name=3Dwget
[dbserver]
10.2.1.200
10.2.2.201
[dbserver:vars=
]
pkg_name=3Dapa=
che2
Write a
     playbook to install the package using host vars
---
-
hosts: webserver
become:
yes
tasks:
- name: print the variable
debug:
msg: The variable pkg_name=
 is: "{{
pkg_name }}"
o/p:-
The
variable pkg_name is: wget
Write a
     playbook to install the package using group vars
---
-
hosts: dbserver
become:
yes
tasks:
- name: print the variable
debug:
msg: The variable pkg_name=
 is: "{{
pkg_name }}"
o/p:-
The
variable pkg_name is: apache2
Priori=
ty
     levels of variable
0 --> group=
_vars
1 --> host_=
vars
2 --> varia=
ble in playbook
3 --> varia=
ble passed through
the command line
Exampl=
e:
     Maintain variables in
group=
_vars(apache2)
host_=
vars(wget)
playb=
ook(git)
comma=
nd
      line(tree) & test the priority levels
Write a
     playbook & execute
---
-
hosts: all
become:
yes
vars:
pkg_name: git
tasks:
- name: print the variable
debug:
msg: The variable pkg_name=
 is: "{{
pkg_name }}"
exec1-
ansible-playbook
-i hosts -e "pkg_name=3Dtree" -v smp.yml
o/p:
The
variable pkg_name is: tree
exec2:-
ansible-playbook
-i hosts -v smp.yml
o/p:
The
variable pkg_name is: git
exec3:- Disable variable & define host vars =
for
dbserver group also
ansible-playbook
-i hosts -v smp.yml
o/p:
The
variable pkg_name is: wget
exec4:-
ansible-playbook
-i hosts -v smp.yml
o/p:
The
variable pkg_name is: apache2
New wa=
y of
     declaring the group_vars & host_vars
cd
/home/ansible
ls
hosts
group_vars/webserver.yml
host_vars/10.1.2.100.yml
Create=
 host
     file with this contents
The
host file contains details like
[webserver]
10.1.1.100
10.1.1.101
[dbserver]
10.1.2.100
Define
     variables at group level
webserver.yml
---
pkg_name:
git
Define
     variables at host level
10.1.2.100.yml
---
pkg_name:
tree
Provide
     hosts details as web-server & check which package is getting execu=
ted
---
-
hosts: webserver
become: yes
tasks:
- name: print the pkg_name
debug:
msg: value of pkg_name is =
"{{
pkg_name }}"
Exec:
On webserver related nodes git pack=
age
will get installed
Provide
     hosts details as ip-details & check which package is getting execu=
ted
---
-
hosts: 10.1.2.100
become: yes
tasks:
- name: print the pkg_name
debug:
msg: value of pkg_name is =
"{{
pkg_name }}"
Exec: On 10.1.2.100 node tree package will get
installed
Provid=
e all
     hosts & check which package is getting executed
---
-
hosts: all
become: yes
tasks:
- name: print the pkg_name
debug:
msg: value of pkg_name is =
"{{
pkg_name }}"
Exec:
On webserver related nodes git pack=
age
will get installed
On
10.1.2.100 node tree package will get installed
Ansibl=
e-Day-6
13
December 2023
14:=
58
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Ansible vault
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
This feature allows us =
to
     encrypt the sensitive information like passwords & secret key's ra=
ther
     than using it as a plain text in ansible playbooks or roles.
Create=
 a
     file with secret key in plain text
echo
"API_KEY: ThisIsSuperSecretDontDisplay" > vars/api_key.yml
Create=
 a
     sample playbook to display value of the variable API_KEY
---
-
hosts: all
become: yes
vars_file:
-
vars/api_key.yml
tasks:
-
name: "Display the API_KEY value"
debug:
msg:
"{{ API_KEY }}"
ansible-playbook
-v test.yml
o/p:
ThisIsSuperSecretDontDisplay
Let's
     encrypt the vars/api_key.yml file
Encryp=
t the
     file
ansible-vault
encrypt vars/api_key.yml
cat
vars/api_key.yml
The
file whatever present vars/api_key.yml is encrypted now.
cat
vars/api_key.yml
So we can push this fil=
e to
     GitHub along with our playbook/role.
Execute ansible playboo=
k
ansible-playbook
-v test.yml --ask-vault-pass
Execute ansible playboo=
k with
     password stored in a file
ansible-playbook
-v test.yml --vault-password-file
Having a separate scrip=
t file
     for getting the passwords is also possible.
you
need to make sure the script file is executable and the password is printed=
 to
standard output for it to work without annoying errors.
ansible-playbook
launch.yml --vault-password-file ~/ .vault_pass.py
Decryp=
t the
     file
ansible-vault
decrypt vars/api_key.yml
View an Encrypted File =
in
     Ansible
ansible-vault
view vars/api_key.yml
Edit an Encrypted File =
in
     Ansible
ansible-vault
edit vars/api_key.yml
Change the password for=
 the
     encrypted file
ansible-vault
rekey vars/api_key.yml
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
What is ansible role?
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
1. Normally wh=
en we
write playbook for particular requirement we mention everything in a single
file
like
-
tasks
-
variables
-
handlers
-
metadata
2. Ansible rol=
es
allow you to develop reusable automation components by grouping related
automation things,
-
configuration files
-
templates
-
tasks
-
handlers
3. Roles will =
have
structured layout.
4. Ansible rol=
es
consists of multiple folders & each folder by default contains main.yml
file.
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
How to create a role
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
1. Create ansi=
ble
role for apache-setup
ansible-galaxy
init apache-setup
2. The role
structure of the apache-setup will be like
apache-setup
├──
defaults
│
└──
main.yml
├──
files
├──
handlers
│
└──
main.yml
├──
meta
│
└──
main.yml
├──
README.md
├──
tasks
│
└──
main.yml
├──
templates
├──
tests
│
├──
inventory
│
└──
test.yml
└──
vars
└──
main.yml
3. Now let's
understand every folder purpose,
a.
defaults/main.yml =3D=3D> In this configuration file we declare default =
values
for the variables.
Example: httpd is the default package =
name
for installing apache on Linux machine,
so we will declare it as variable here=
.
b.
files =3D=3D> We copy the static files like .tar.gz/.zip files into this
directory.
During ansible role ex=
ecution files
that are present over here will be transfer to target machine.
c.
handlers/main.yml =3D=3D> In this section we will declare handlers like =
restart
apache.
d.
meta/main.yml =3D=3D> It's metadata file, which contains the information=
 like
-
author
-
license
-
dependency management
From this we can another dependency rol=
e for
current apache-setup role.
Example:
Let's assume we have two roles for maven-setup & java-setup
When
we create maven-setup role, we can make java-setup role as dependecy in
meta/main.yml
e.
README.md =3D=3D> In this file we write Description about the role &=
 its
usage.
f.
tasks
=3D=3D> In this folder w=
e will
create the list of the .yml files related to our activities
Example:
Installing
apache {apache.yml}
Configure
apache {configure.yml}
g.
templates =3D=3D> This folder contains the template files(jinja2) used b=
y the
role to create the actual configuration files.
Example: After installation there might=
 be
need to update the configuration files as well,
like including usernam=
es/os-details
in-order to do this we will use templates.
h.
vars =3D=3D> Used to declare the variables that are needed for ansible p=
laybooks
Here
we can see variables we can declare at defaults/main.yml & vars/main.ym=
l.
The
variables which are declared in vars/main.yml have high priority.
4. Create a ansible for
apache-setup & push it GitHub
Docker=
-Day-1
14
December 2023
10:=
12
What a=
re
     VM's?
The
EC2 instances that we created on AWS management console are considered as V=
M's
How th=
ese
     VM's are created?
We just go to the AWS
     management console & click launch instance, correct right? - Yes
But in background we wi=
ll
     discuss what will happen,
Assume there is
=
physic=
al
     server
with
     Linux OS on datacentre with good amount of
CPU
RAM
HD
Network utilities
Whatever machine that
     physically present it can be considered as physical server.
I mean laptop/any comp=
uters
On top physical server
     Hypervisor software is installed.
What
     Hypervisor software will do?
This helps to create virtual machines.
On these virtual we can
     install OS like
RHEL
Ubuntu
Windows
On top of these OS we w=
ill
     install s/w's (or) binaries (or) libraries, assume on
VM1 we installed Tomca=
t
VM2 we installed Java<=
/span>
VM3 we installed IIS
Post that we deploy
     applications on these VM's
VM1 =3D=3D> Tomcat =
=3D=3D> War
VM2 =3D=3D> Java =
=3D=3D> .jar
VM3 =3D=3D> IIS =3D=
=3D>
      .Net
application
What i=
s the
     problem that may happened with VM's?
In real
     time, how will bring any application to the live environment?
First,
we will deploy application into DEV environment & next we will deploy t=
he
application into QA environment & finally we will deploy application in=
to
production environment, Correct or not? - Correct
Assume=
 you
     have a Java web application called Online Bookstore and you want to ta=
ke
     it live.
Once the developers com=
pleted
     the coding part, as a DevOps engineer will generate a binary file call=
ed
online=
-bookstore.war
file.
This
file we will deploy into DEV environment VM first.
To dep=
loy
     java application on DEV environment what is required?
We
will create a VM with Linux OS on top of that tomcat software & finally=
 we
will deploy the Java application.
So,
post deployment the developers will do the testing & confirmed the
application is working fine in DEV environment & asked to promote into =
QA
environment.
As a DevOps engineer ag=
ain,
     we will create a VM to the QA environment with Linux OS, tomcat softwa=
re
     & finally deploy application into QA environment.
Here again, the QA engi=
neer
     will do the testing.
During
QA testing identified a lot many issues, so simply QA engineer will create a
bug in the JIRA & will assign to developers.
Now the developers will
     replies, there is no issues in the code at their side & the
     application also working fine in the dev environment. This might be
     configuration issues at QA VM itself.
Now who did this
     configuration of VM like software installation, and deployment? DEVOPS
     ENGINEER
So devops engineer will=
 check
     all software's are installed or not in QA VM & since all software's
     installed simply revered the mail/ticket to DEVELOPERS there are no
     configuration issues at QA VM side.
Like this conversation
     happened between developers & ops person for couple of days.
One fine day the was is=
sue
     identified, the tomcat version is different in both servers.
Due
to this environment mismatching some of the future not working in the QA
environment which are working in the development.
Finally time got wasted=
 this
     kind of environmental issues.
To avoid this kind of
     situations containers came into picture.
What
     containers will do?
Containers will have t=
he
      software's that are needed to run your application & Artifact of =
the
      application code.
Now the probability for
     getting errors related to the environment changes between different
     environments very less, since we packed the .war file & tomcat
     software. Simply we can container on any environment & can access
     application.
Now let's see how to cr=
eate
     containers in background.
Assume this is a physic=
al
     server or VM with good amount of RAM, CPU and hard disk on top of that=
RHEL was installed &am=
p;
      again on top of that docker is installed. So, this
docker
      software what it will do, it will help you create the containers.
Let's create containers=
container-1
container-2
container-3
Assume on these contain=
ers we
     install libs/bin's & finally we deploy our application.
On container-1 we can i=
nstall
     tomcat binary & deploy java web application .war file.
On container-2 we can i=
nstall
     java binary & deploy java application .jar file
On container-3 we can i=
nstall
     IIS & deploy .Net application .jar file
These containers are
     independent each other & we can create n-no of containers on single
     VM.
You ma=
y have
     doubt how containers will work with-out OS?
Container
will communicate directly with the OS of physically as read only.
For your easy understan=
ding
     following are containers in real-time,
Shipping container
Lunch box
Makeup box
Here containers like the
     boxes for us & the
items that present in boxes
/containers are conside=
red as
applications
     & dependencies needed
for project.
Now le=
t's
     see how to containers practically.
To create any docker
     container we require
docker image
.
What is
     docker image?
It's a read only templ=
ate
      which contains the list of instructions to create the container.
Suppose you want to c=
reate
       Ubuntu OS container you can find Ubuntu image &
Same way if you want =
to
       create tomcat container we need tomcat docker image.
Where =
do
     this docker images stored?
That docker images will
      stored under the registry called Docker Hub.
In the Docker hub we c=
an
      find docker images for any software.
Let's search for
Ubun=
tu
docker image here we=
 can
       find n-no.of docker images created by different people.
Same way if you searc=
h
jenk=
ins
you can find jenkins
       docker image details
Out of these docker i=
mages
       we will only the
Official
Image which is maintained docker community.
You may have doubt wh=
at are
       the rest of the docker images?
Those are docker ima=
ge
        created by the
people like us & pushed into Docker hub
. We see this part o=
n next
        sessions.
How to list the active
     containers that running in VM
docker ps
Since
we don’t have any active docker container we don't see any output.
Now the run the
=
docker=
 ps -a
This
command will help to list the inactive & active containers, present we
don't have any active/inactive container. So the output is nothing.
Let's
Create
     Ubuntu container on docker
, for that
first
     we need to
Downl=
oad
      Ubuntu docker image from docker hub
to the server, for that we will go Docker hub &
      look for docker image Ubuntu
Next
we will run
docker pull ubuntu
If
I don't mention anything after ubuntu by default latest docker image will be
picked & if we mention specific tag particular docker image will be
downloaded.
Based on this output we=
 can
     confirm docker image is downloaded but to confirm what docker images
     available or not on the server run command
docker images
Ubuntu image is ready on
     server & we can create Ubuntu container based on this by running
     command
docker run ubuntu
Now we can check contai=
ner is
     running or not with the command
docker ps
To con=
nect
     actively running container
docker
exec -it <cid> /bin/bash
Only we can login to th=
e OS
     related containers.
Now we are inside the
     container & here we can see the
login user on VM was
      ec2-user but now we are under root
file system structure =
is
      also different now.
To come-out this contai=
ner we
     can enter a command exit, now we are on the server.
If you=
 run
     docker ps command we don't see any docker containers, what happened?
After click on exit in docker container, it will=
 be
automatically stopped
. You can find stopped container using
docker
ps -a
If you=
 want
     to connect container & come outside of it without stopping contain=
er
     we will see now.
Create new docker conta=
iner
     from Ubuntu image
docker
run Ubuntu
Connect to docker conta=
iner
docker
exec -it <cid> /bin/bash
To exit from container =
type
Ctrl
+ p +q
We can stop actively ru=
nning
     container in docker using
docker
stop <cid>
We can also start conta=
iner
     by running
docker
start <cid>
To remove the container=
 from
     VM
docker
rm <cid>
If you want to delete
     actively run command
docker
rm -f <cid>
Same way if you want to
     remove the docker images present on server
docker
rmi <image_name>
If you want to remove a=
ll the
     docker images
docker
rmi -f (docker images -q)
Docker=
-Day-2
22
December 2023
19:=
34
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Docker volumes
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Normally the data insid=
e the
     docker container will be deleted automatically if container
     stopped/killed.
In order to make the da=
ta
     that was present inside the container even after the container
     stopped/killed we use docker volumes.
Now let's practically s=
ee
     whether data loss will happen or not after container destroy
Create
a container & login
docker
run -it Ubuntu /bin/bash
echo
"Testing the data storage availability" > /storage. out
cat
/storage.out
Suppose if we kill/exit=
ed
     container the /storage.out file also deleted, but in real-time there w=
ill
     be a situations we need to have file/data present inside the container=
.
exit
the container & we will not able to see the /storage.out file.
So docker volumes will =
help
     here
There are different way=
s of
     using docker volumes
Anony=
mous
      volumes
Named
      volumes
host =
based
      volumes
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Anonymous volumes
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Create=
 a
     container a with mount point /data_01 & the data/files present und=
er
     /data_01 will be accessible on docker host if container destroyed.
docker
run -it --name myubutnu -v /data_01 ubuntu:latest
To know
more d=
etails
     about docker containers
we use inspect command,
docker inspect mybuntu
The output of the docker
     inspect command is in json format.
Here in
mount
     section we find the source tag which present on docker host machine
& pointing to the =
/data_=
01
of docker container.
So Inside the docker
     container under /data_01 if we create any file that will show in docker
     host
on path
     /var/lib/docker/volumes/8491375021/_data
And same if we create a=
ny
     files/directory inside docker host machine will be showed in container=
 as
     well.
Now kill the container =
&
     check whether the data of container is present on docker host or not.<=
/span>
With this method we wil=
l get
     confused to which volume the container was used if we have many
     containers.
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
Named volumes
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
During=
 named
     volumes we provide name for the docker volume on host machine
docker
run -it --name myubutnu -v volume_test:/data_01 ubuntu:latest
To know more details ab=
out
     docker containers we use inspect command,
docker
inspect myubuntu
The output of the docker
     inspect command is in json format.
Here
in mount section we find the source tag which present on docker host machine
& pointing to the /data_01 of docker host.
We
can observe volume name generated as volume_test
So Inside the docker
     container under /data_01 if we create any file that will show in docker
     host /var/lib/docker/volumes/8491375021/_data
And same if we create a=
ny
     files/directory inside docker host machine will be showed in container=
 as
     well.
Now kill the container =
&
     check whether the data of container is present on docker host or not.<=
/span>
With this method we wil=
l get
     confused to which volume the container was used if we there many
     containers
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
host based volumes
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
In this method we will =
mount
     specific directory on docker host machine to docker container.
<=
/li>
Create new directory on=
 host
     machine
mkdir
/root/volume-test
Mount the new
     directory(/root/volume-test) as mountpoint(/data_01) inside the contai=
ner
docker
run -it --name volume_test3 -v /root/volume-test:/data_01 ubuntu:latest
Create a file inside the
     docker container on /data_01
mkdir
IamInsideContainer
On new terminal check t=
he
     directory "IamInsideContainer" present or not under
     "/root/volume-test"
cd
/root/volume-test
ls
Create new directory on=
 host
     under /root/volume-test
cd
/root/volume-test
mkdir
IamOutSideContainer
Verify inside docker
     container IamOutSideContainer folder present or not under /data_01
cd
/data_01
ls
Stop & kill the con=
tainer
docker
stop <container_id>
docker
rm <container_id>
Verify the files which =
are
     present under /data_01 directory of container are not lost.
cd
/root/volume-test
ls
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
Port Mapping
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
Normally every applicat=
ion
     runs on a specific port.
Like
tomcat will run on port=
 8080
sonarqube will run on p=
ort
     9000
Similarly when we spin
     container for any application it will run particular port,
We
can't directly connect to the docker container via port, so we will bind do=
cker
container exposed port with host machine port.
docker run -it -p 8888:8080 tomcat
Docker=
-Day-3
22
December 2023
19:=
51
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D
dockerfile
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D
It is a normal script f=
ile
     contains the set of instructions which are useful to build a Docker im=
age.
dockerfile =3D=3D> d=
ocker
     image =3D=3D> container
Now let's instructions =
that
     we use inside the dockerfile
=3D=3D=3D=3D=
=3D
FROM
<=
/span>
=3D=3D=3D=3D=
=3D
In every dockerfile the=
 first
     line is
FROM
instruction.
The
FROM
used to pull the base =
image
     & that we are looking to customize it.
Search of dockerfile in
     internet we can use every file started with from instruction.
Ex:-
FROM
ubuntu:latest
=3D=3D=3D=3D=
=3D=3D
LABEL
=3D=3D=3D=3D=
=3D=3D
LABEL instruction used =
to
     stores meta data information about docker Image, like who is the autho=
r of
     the Docker Image.
As best practice purpos=
e only
     we use LABEL instruction.
Ex:-
LABEL
owner chaitanya
LABEL
team XYZ
=3D=3D=3D=3D=
=3D
RUN
=
=3D=3D=3D=3D=
=3D
RUN instruction used ex=
ecute
     shell commands, I mean any Linux commands
Ex:-
RUN
apt-get install wget -y
RUN
apt-get install tree -y
RUN
apt-get install vim -y
usecase-1:
Create a custom docker =
image
     with git presence
FROM
ubuntu:latest
LABEL
owner chaitanya
RUN
apt-get install git -y
To Create docker image =
based
     out of the docker file we use command
docker
build -t custom_git:latest -f dockerfile
docker
images
docker
run -it custom_git:latest /bin/bash
git
--version
usecase-2:
Use single RUN instruct=
ion
     for instead of multiple run instructions
Way-1
FROM
ubuntu:latest
LABEL
owner chaitanya
RUN
apt-get install git -y
RUN
apt-get install wget -y
RUN
apt-get install tree -y
RUN
apt-get install vim -y
Way-2
FROM
ubuntu:latest
LABEL
owner chaitanya
RUN
apt-get install git -y && \
apt-get install wget -y &&=
 \
apt-get install tree -y &&=
 \
apt-get install vim -y
=3D=3D=3D=3D=
=3D
CMD
=3D=3D=3D=3D=
=3D
CMD instruction is used=
 to
     provide default command & parameters to docker container.
We can easily override =
the
     default commands that are mentioned in CMD while spinning up container=
.
If we have multiple CMD
     instructions in dockerfile the last CMD instruction only will be appli=
ed.
Usecase3: Create docker image with default echo
command for docker container using CMD
Create
     docker file
FROM
ubuntu
LABEL
Chaitanya
RUN
apt-get update
CMD
["echo", "Hello World"]
The each string in shell
     command will be double quoted, then only CMD will consider it as comma=
nd.
Create
     docker image
docker
build -t basic_cmd:1.0 -f dockerfile
docker
images
docker
run -d basic_cmd:1.0
The container will gets
     spin-up & execute the default echo command inside container &
     container will get stopped automatically since there is no long running
     command inside it.
Usecase4: Create docker image such way that it s=
hould
be up & running as long you stop it explicitly using CMD
Create
     docker file
FROM
ubuntu
LABEL
owner chaitanya
RUN
apt-get update -y
RUN
apt-get install iputils-ping -y
CMD
["ping", "google.com"]
Create
     docker image
docker
build -t basic_cmd:2.0 -f dockerfile
docker
images
docker
run basic_cmd:2.0
Usecase5:- Override the shell commands in CMD
instruction
docker run basic_cmd:2.0
     hostname
The hostname command
     overrides the default ping command & prints the hostname of the
     container.
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D
ENTRYPOINT
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D
Similar to CMD instruct=
ion,
     ENTRYPOINT instruction also is used to provide default command &
     parameters to docker container.
What i=
s the
     difference between CMD and ENTRYPOINT?
You cannot override the
      ENTRYPOINT instruction by adding command-line parameters to the docker
      run command.
Arguments passed to do=
cker
      run are treated as arguments to the ENTRYPOINT command.
FROM
ubuntu
ENTRYPOINT
["ping", "-c", "4"]
docker run myimage google.com
→
Runs
ping -c 4 google.com
We use Entrypoint instr=
uction
     when we have a fixed command that will always be executed & which
     can't be overwritten
ENTRYPOINT
["nginx", "-g", "daemon off;"]
Usecase6:- Create docker image with default echo
command for docker container using ENTRYPOINT
Create
     docker file
FROM
ubuntu
MAINTAINER
sofija
RUN
apt-get update
ENTRYPOINT
["echo", "Hello World"]
Create
     docker image
docker
build -t basic_entrypoint:1.0 -f dockerfile /root
docker
images
docker
run basic_entrypoint:1.0
Prints the Hello World =
&
     container will be stopped automatically
Usecase7:- Create docker image such way that it =
should
be up & running as long you stop it explicitly using CMD
Create
     docker file
FROM
ubuntu
LABEL
owner chaitanya
RUN
apt-get update -y
RUN
apt-get install iputils-ping -y
ENTRYPOINT
["ping", "google.com"]
Create
     docker image
docker
build -t basic_entrypoint:2.0 -f dockerfile /root
docker
images
docker
run basic_entrypoint:2.0
Usecase8:- Try to override the shell commands in
ENTRYPOINT instruction
docker run
     basic_entrypoint:2.0 hostname
The hostname command ju=
st
     append as string to the default ping command & prints the hostname=
Usecase9:- Using CMD + ENTRYPOINT
Create
     docker file
FROM
ubuntu
LABEL
Chaitanya
RUN
apt-get update
ENTRYPOINT
["echo", "Hello"]
CMD
["World"]
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D
WORKDIR
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D
WORKDIR instruction use=
d to
     define the working directory of a Docker container at any given time.<=
/span>
Ex:- Create dockerfile & image based out of =
it
without workdir instruction
FROM
ubuntu:latest
RUN
apt-get update -y
RUN
apt-get install git -y
RUN
touch 1.out 2.out 3.out
Create docker image
docker
build -t custom_img:latest .
docker
run -it custom_img:latest /bin/bash
Here the we can observe=
 that
     the default working directory "/" & files are created un=
der
     "/"
Usecase10:- Create a custom WORKDIR
Create
     docker file
FROM
ubuntu:latest
WORKDIR
/project
RUN
apt-get update -y
RUN
apt-get install git -y
RUN
touch 1.out 2.out 3.out
Here the we can observe=
 that
     the default working directory "/project" & files are cre=
ated
     under "/project"
=3D=3D=3D=3D=
=3D
ADD
=3D=3D=3D=3D=
=3D
The ADD command is used=
 to
     copy files/directories into a Docker image. It can copy data in three
     ways:
Copy files from the loc=
al
     storage to a destination in the Docker image.
Copy a
tar b=
all
     from the local storage and extract
it automatically inside a destination in the Docker
     image.
Copy files from a URL t=
o a
     destination inside the Docker image.
Ex:-
Create=
 a
     docker image to copy files from VM to docker container
FROM
ubuntu:latest
WORKDIR
/project
RUN
mkdir test
ADD
codes /project/test
ADD
abc.out /project/test
ADD
samp.tar.gz /project/test
=3D=3D=3D=3D=
=3D
COPY
=3D=3D=3D=3D=
=3D
The COPY command is use=
d to
     copy files/directories into a Docker image. It can copy data in three
     ways:
Ex:-
FROM
ubuntu:latest
WORKDIR
/project
RUN
mkdir test
COPY
codes /project/test
COPY
abc.out /project/test
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D
EXPOSE
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D
EXPOSE instructions inf=
orms
     the docker that the container listens on specific port at runtime.
Jenkins container will
     listens on port 8080
Ex:-
EXPOSE
8080
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D
Usercase10: Build tomcat docker image with deplo=
yable
package
=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D
Take Ubuntu as base ima=
ge
Install tomcat inside d=
ocker
     Image
Copy the sample war Art=
ifact
Expose port 8080, since
     tomcat listens on port 8080
Run tomcat as service
Way-1
FROM
Ubuntu
LABEL
OWNER Chaitanya
RUN
mkdir /opt/tomcat/
WORKDIR
/opt/tomcat
RUN
curl -O
https://www-eu.apache.org/dist/tomcat/tomcat-8/v8.5.40=
/bin/apache-tomcat-8.5.40.tar.gz
RUN
tar xvfz apache*.tar.gz
RUN
mv apache-tomcat-8.5.40/* /opt/tomcat/.
RUN
yum -y install java
RUN
java -version
WORKDIR
/opt/tomcat/webapps
RUN
curl -O -L
https://github.com/AKSarav/SampleWebApp/raw/master/dist/SampleWebApp=
.war
EXPOSE
8080
CMD
["/opt/tomcat/bin/catalina.sh", "run"]
Way-2: Actually you don't need to install tomcat=
 on
Ubuntu we have docker image for tomcat itself, for your understanding on
instructions I craeted dockerfile based on Ubuntu image
FROM tomcat:8.0-alpine
=
LABEL maintainer=3D”abc@gma=
il.com”
ADD sample.war
/usr/local/tomcat/webapps/
EXPOSE 8080
CMD [“catalina.sh”, “ru=
n”]
=3D=3D=3D=3D=
=3D=3D
ARGS
=3D=3D=3D=3D=
=3D=3D
ARG instruction defines=
 the
     variables during docker image creation.
Usecas=
e:
     Define variable & call it inside the dockfile using ARG instructio=
n
Create
     docker file
FROM
ubuntu:latset
LABEL
chaitanya
WORKDIR
/
ARG
user1 chai
RUN
echo $user1 > user_name.out
Create
     docker image
docker
build -t myarg:1.0 .
docker
run -it myarg:1.0 /bin/bash
cat
/user_name.out
Override the user1 valu=
e
docker
build -t myarg:2.0 --build-arg user1=3Dtom .
=3D=3D=3D=3D=
=3D=3D
ENV
=3D=3D=3D=3D=
=3D=3D
ENV instruction is used=
 to
     set the Environment variables(system-level/user-level in windows) for =
the
     future containers which are created from custom docker image.
FROM
ubuntu:latest
WORKDIR
/project
ENV
http_proxy
http://10.0.0.0:8000
RUN
echo $http_proxy
=3D=3D=3D=3D=3D=3D
<=
/p>
VOL(use c=
ase
step required)
=3D=3D=3D=3D=3D=3D
<=
/p>
Create a volume inside a container & persist data even
     container killed/terminated
FROM ubuntu:latest
<=
/p>
RUN mkdir /data
WORKDIR /data
RUN echo "Hello from
Volume" > test
VOLUME /data
Home work:
Dockerize jar & spin =
up
     container & access application
Automate the ci/cd proc=
ess
Maven build
Sonar-scanning
<=
/li>
Dockerize war file
Push docker image to d=
ocker
      registry
Deploy image &Spin=
 as
      container
Access the application=
DEVOPS
Syllabus
04 =
March
2024
21:=
38
=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
DEVOPS
=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
I=
ntroduction
about DEVOPS
L=
inux:
• Linux Introduction & architecture
• Setup AWS Account & Linux server provision
• Basic Linux commands - file/dir. creation, cp, mv..etc
• User management & soft link/Hardlink
• Permissions management & Package management
G=
it:
• Git and GitHub repository creation
• Git commands - all 21 commands with practical
• working with Linux and windows environment
• working with java code on Git and GitHub.
M=
aven:
• Build the code using maven tool
• maven dependencies
• maven repository
• maven lifecycle/phases
• java artifacts.
• pom.xml configuration
S=
onarqube:
• Sonarqube server setup & Purpose of sonarqube setup
• Publish sonarqube reports to sonarqube server
• Setup quality gates
• Quality profile setup
J=
enkins
• Continuous integration
• Jenkins overview
• Jenkins installation
• dependencies of jenkins
• Job configuration
o Free style job
o Pipeline job
• scripted pipeline
• declarative pipeline
• Plugin management
• Global tool configuration and integration
• Security in jenkins
o global security
o user management
o credential management
o role based authorization
• master slave configuration
• GitHub web hook with jenkins.
• maven and other tool configuration
• Jfrog integration
J=
FROG:
• Artifactory management
• Jfrog overview
• Jfrog installation
• types of repository in Jfrog
• creating maven repository
• integrating with jenkins and push the artifact to Jfrog.
A=
nsible
• Continuous delivery/deployment
• Configuration management
• push based/pull based, agent based/agentless
• Ansible overview
• IT orchestration
• Ansible installation
• Playbook
o YAML basics
o Modules
o Roles
o Galaxy
o tasks
o variables
o Adhoc cmd execution
• Tower
• Inventories
o Static inventory
o Dynamic inventory
• Playbook to install any package in target
• playbook to CD operation
D=
ocker:
• Containerization
• difference between container and VM
• Docker components
• Docker daemon/engine/client
• Docker container
• docker images
• dockerfile
• Docker hub
• docker port
• docker volume
• docker instructions
• write dockerfile to create an apache image.
• dockeri
z
ing an
application by writing the dockerfile
• managing the images in Docker hub
• Deploying the application in web - apache server
• deploying spring boot application in tomcat server.
K=
ubernetes:
• overview and high-level session.
• What is pod
deploy
service
ingress
ConfigMap
P=
roject1:
CI & CD pipeline setup using jenkinsfile into Kubernetes by handling the
different environments
P=
roject2:
Handling the CI/CD pipeline with different branching strategy into dev/qa/p=
rod
environments
Linux-=
Day-7
18 =
March
2024
22:=
35
Shell script is used to
     automate the repeated tasks that we do daily basis on servers.
<=
/li>
Checking the =
file
      system size on server
Install of software &a=
mp;
      configuration.
Shell script
files are usually with extension =
.sh
Example:
sample.sh / file_system_size_check.sh
The shell script file
     contains the Linux commands in sequence format in order to achieve
     particular requirement like checking file system size.
Usecase1=
:
Now I will write sample
     shell script to print date & time using shell script
vi
get_today_date.sh
#!/bin/bash
echo
"Today date & time is:" $date
Ignore
the first line whatever I mentioned over here & will discuss
about it after sometime .
Now
let see how to execute this script file
./get_today_date.sh
Useacase2:
Next we will discuss about how to
     declare variable & call it
vi
variables_usage.sh
#!/bin/bash
age
=3D 10
name
=3D "chaitu"
Echo
"The value of a is: " $a
Echo
"The value of name is: " $name
Usecase3: In above script
     file we are hardcoded the values of a & name variables, normally we
     shouldn't hardcode the values & instead of that we pass the values=
 to
     variables during script execution.
#!/bin/bash
name=3D$1
age=3D$2
Echo
$name age is: $age
./print_person_age.sh
chaitu 28
The
values that I given during
Command line arguments
Take
example from tutorials
Example: Chck
Maven-=
Day-2
29 =
March
2024
12:=
44
Connect to database
psql -h <endpoint> -p 5432 -U <username> -d
     <database_name>
psql -h kodo-sienna.cvii02ai6sn1.us-east-1.rds.amazonaws.com -p 5=
432
     -U postgres -d postgres
If there are any connectivity issues create a security for allowi=
ng
     5432 port and assign it to the DB instance
Create
     database in postgres
CREATE DATABASE kodo_sienna;
List
     the databases \l
Exit session \q
Steps to conne=
ct
EKS
1. Install aws cli & kubectl
aws configure
AWS
Access Key ID [None]: AKIA4IM3HEIAH33LE5MC
AWS
Secret Access Key [None]: 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
Default
region name [None]: us-east-1
Vault<=
/p>
18 =
March
2025
11:=
03
Launch amazon
      linux instance
Install vault
yum
 install -y yum-utils shadow-utils
yum-config-manager
 --add-repo
htt=
ps://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
yum
 -y install vault
Start vault server
vault server -dev -dev-listen-address=3D"0.0.0.0:8200"=
;
Open new sess=
ion
      & execute
export VAULT_ADDR=3D'http://127.0.0.1:8200'
To login vault as root
      user
vault login <root-token>
Enable KV secret engin=
e with
      custom path
vault secrets enable
      -path=3Dgcp/au/kv/nonprod kv
Add secrets into vault=
vault kv put gcp/au/kv/nonprod/assetfinance/sienna userid=3Dcha=
itu
      passid=3Dab123cd
Create policy to
      read/write/update/delete secrets from custom path
or secrets location
vault
 policy write
nonprod-assetfinance-sienna<=
/span>
 - <<EOF
path
 "gcp/au/kv/nonprod/assetfinance/sienna/*" {
capabilities =3D ["read",
 "list", "create", "update", "delete&quo=
t;]
}
EOF
Enable kubern=
etes
      authentication in vault
vault auth enable kubernetes
Setup EKS cluster
eksctl create cluster --name my-eks-cluster --region us-east-1
      --nodes 1 --nodegroup-name service-nodes
Connect to EKS cluster=
aws eks update-kubeconfig --region us-east-1 --name
      my-eks-cluster
Create namespace and s=
witch
      to it
kubectl create namespace bdx-sienna
kubectl config set-context --current --namespace=3Dbdx-sienna
Configure vau=
lt
      to communicate with K8s
vault write auth/kubernetes/config \
token_reviewer_jwt=3D/root/token =
\
kubernetes_host=3D"https://35EEF3FB8A750794F1CB11DB25C3E5BA.gr=
7.us-east-1.eks.amazonaws.com"
 \
kubernetes_ca_cert=3D/root/ca.crt=
Capture
      kubernetes_host url
kubectl cluster-info
Extract servi=
ce
      account token & ca.crt [Basically these are present in path
      /var/run/secrets/kubernetes.io/serviceaccount inside a POD]
kubectl crea=
te
       serviceaccount bdx-sienna-svc-acct -n bdx-sienna
Do sample deployment =
for
       fetching token & ca.crt
---
apiVersion: v1
kind: Pod
metadata:
name: token-extractor
namespace: default
spec:
serviceAccountName:
 bdx-sienna-svc-acct
containers:
- name: busybox
image: busybox
command: ["sh&quo=
t;,
 "-c", "sleep 3600"]
Copy the token
      & ca.crt from pod to machine
#
 Copy the token
kubectl
 cp pod/token-extractor:/var/run/secrets/kubernetes.io/serviceaccount/token
 /tmp/token
#
 Copy the CA certificate
kubectl
 cp
 bdx-sienna/token-extractor:/var/run/secrets/kubernetes.io/serviceaccount/c=
a.crt
 /tmp/ca.crt
Then run the =
vault w=
rite
      auth/kubernetes/config
command in step-13
Define a role
      that maps k8s service account with the vault
vault
 write auth/kubernetes/role/
bdx-sienna-rol=
e
\
bound_service_account_names=3Dbdx-sienna-svc-acct \
bound_service_account_namespaces=3Dbdx-sienna \
policies=3D
nonprod-assetfinance-sienna
\
ttl=3D1h
Deploy an app
      & access the secrets from vault
Create confi=
gmap
       using config.hcl [Better use dos2unix config.hcl any formatting
       issues]
Created with Microsoft OneNote 2016.